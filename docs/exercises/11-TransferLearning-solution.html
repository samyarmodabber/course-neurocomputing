<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Neurocomputing - 35&nbsp; Transfer learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../exercises/12-VAE-solution.html" rel="next">
<link href="../exercises/10-CNN-solution.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Transfer learning</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../" class="sidebar-logo-link">
      <img src="../notes/img/tuc-new.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Neurocomputing</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Overview</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true"><strong>Introduction</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.1-Introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.2-Math.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Math basics (optional)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.3-Neurons.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Neurons</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true"><strong>Linear algorithms</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.1-Optimization.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.2-LinearRegression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.3-LinearClassification.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Linear classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/2.4-LearningTheory.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Learning theory</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true"><strong>Neural networks</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.1-NeuralNetworks.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Multi-layer perceptron</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/3.2-DNN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Modern neural networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true"><strong>Computer Vision</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.1-CNN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Convolutional neural networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.2-ObjectDetection.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Object detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/4.3-SemanticSegmentation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Semantic segmentation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true"><strong>Generative modeling</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/5.1-Autoencoders.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Autoencoders</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/5.2-RBM.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Restricted Boltzmann machines (optional)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/5.3-GAN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Generative adversarial networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true"><strong>Recurrent neural networks</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/6.1-RNN.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Recurrent neural networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/6.2-NLP.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/6.3-Attention.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Attentional neural networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true"><strong>Self-supervised learning</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/7.1-Transformers.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/7.2-ContrastiveLearning.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Contrastive Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true"><strong>Outlook</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/8.1-Limits.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Limits of deep learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/8.2-Beyond.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Beyond deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true"><strong>Exercises</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Content.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">List of exercises</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/Installation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Python installation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/1-Python-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction To Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/2-Numpy-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Numpy and Matplotlib</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/3-LinearRegression-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/4-MLR-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Multiple linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/5-Crossvalidation-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Cross-validation and polynomial regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/6-LinearClassification-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Linear classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/7-SoftmaxClassifier-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Softmax classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/8-MLP-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Multi-layer Perceptron</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/9-MNIST-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">MNIST classification using keras</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/10-CNN-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Convolutional neural networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/11-TransferLearning-solution.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Transfer learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/12-VAE-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Variational autoencoder</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/13-RNN-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Recurrent neural networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#loading-the-cats-and-dogs-data" id="toc-loading-the-cats-and-dogs-data" class="nav-link active" data-scroll-target="#loading-the-cats-and-dogs-data">Loading the cats and dogs data</a></li>
  <li><a href="#functional-api-of-keras" id="toc-functional-api-of-keras" class="nav-link" data-scroll-target="#functional-api-of-keras">Functional API of Keras</a></li>
  <li><a href="#training-a-cnn-from-scratch" id="toc-training-a-cnn-from-scratch" class="nav-link" data-scroll-target="#training-a-cnn-from-scratch">Training a CNN from scratch</a></li>
  <li><a href="#data-augmentation" id="toc-data-augmentation" class="nav-link" data-scroll-target="#data-augmentation">Data augmentation</a></li>
  <li><a href="#transfer-learning" id="toc-transfer-learning" class="nav-link" data-scroll-target="#transfer-learning">Transfer learning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-title">Transfer learning</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>The goal of the exercise is to investigate data augmentation and transfer learning on a very small dataset (2000 training images).</p>
<p>The code is based on the keras tutorial:</p>
<p><a href="https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs" class="uri">https://keras.io/guides/transfer_learning/#an-endtoend-example-finetuning-an-image-classification-model-on-a-cats-vs-dogs</a></p>
<p>The data is provided as part of a Google tutorial:</p>
<p><a href="https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb" class="uri">https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb</a></p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="loading-the-cats-and-dogs-data" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-cats-and-dogs-data">Loading the cats and dogs data</h2>
<p>The data we will use is a subset of the <a href="https://www.kaggle.com/c/dogs-vs-cats/data">“Dogs vs.&nbsp;Cats” dataset</a> dataset available on Kaggle, which contains 25,000 images. Here, we use only 1000 dogs and 1000 cats to decrease training time and make the problem harder.</p>
<p>The following cell downloads the data and decompresses it in <code>/tmp/</code> (it will be erased at the next restart of your computer).</p>
<div class="cell" data-outputid="9304476e-1b3f-483a-827f-dc7a21d5370b" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">--</span>no<span class="op">-</span>check<span class="op">-</span>certificate <span class="op">\</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    https:<span class="op">//</span>storage.googleapis.com<span class="op">/</span>mledu<span class="op">-</span>datasets<span class="op">/</span>cats_and_dogs_filtered.<span class="bu">zip</span> <span class="op">\</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span>O <span class="op">/</span>tmp<span class="op">/</span>cats_and_dogs_filtered.<span class="bu">zip</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>local_zip <span class="op">=</span> <span class="st">'/tmp/cats_and_dogs_filtered.zip'</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>zip_ref <span class="op">=</span> zipfile.ZipFile(local_zip, <span class="st">'r'</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>zip_ref.extractall(<span class="st">'/tmp'</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>zip_ref.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--2022-11-15 10:29:45--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4005:801::2010, 2a00:1450:4005:80b::2010, 2a00:1450:4005:802::2010, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4005:801::2010|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 68606236 (65M) [application/zip]
Saving to: ‘/tmp/cats_and_dogs_filtered.zip’

/tmp/cats_and_dogs_ 100%[===================&gt;]  65,43M  5,39MB/s    in 14s     

2022-11-15 10:29:59 (4,61 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]
</code></pre>
</div>
</div>
<p>All we have is a bunch of <code>*.jpg</code> images organized in a training and validation set, separated by their binary class dog vs.&nbsp;cat:</p>
<pre><code>cats_and_dogs_filtered/
    train/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
            ...
    validation/
        dogs/
            dog001.jpg
            dog002.jpg
            ...
        cats/
            cat001.jpg
            cat002.jpg
            ...</code></pre>
<p>Feel free to download the data on your computer and have a look at the images directly.</p>
<p>The next cell checks the structure of the image directory:</p>
<div class="cell" data-outputid="fccd4a41-b656-45e5-d68a-d3113381b3ea" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>base_dir <span class="op">=</span> <span class="st">'/tmp/cats_and_dogs_filtered'</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>train_dir <span class="op">=</span> base_dir <span class="op">+</span> <span class="st">'/train'</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>validation_dir <span class="op">=</span> base_dir <span class="op">+</span> <span class="st">'/validation'</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'total training cat images:'</span>, <span class="bu">len</span>(os.listdir(train_dir <span class="op">+</span> <span class="st">'/cats'</span>)))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'total training dog images:'</span>, <span class="bu">len</span>(os.listdir(train_dir <span class="op">+</span> <span class="st">'/dogs'</span>)))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'total validation cat images:'</span>, <span class="bu">len</span>(os.listdir(validation_dir <span class="op">+</span> <span class="st">'/cats'</span>)))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'total validation dog images:'</span>, <span class="bu">len</span>(os.listdir(validation_dir <span class="op">+</span> <span class="st">'/dogs'</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500</code></pre>
</div>
</div>
<p>The next cell visualizes some cats and dogs from the training set.</p>
<div class="cell" data-outputid="98e98e7e-b8c8-4193-9b24-13041c6e9ed2" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.image <span class="im">as</span> mpimg</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">16</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> rng.choice(<span class="dv">1000</span><span class="op">-</span><span class="dv">8</span>, <span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>next_cat_pix <span class="op">=</span> [os.path.join(train_dir <span class="op">+</span> <span class="st">'/cats'</span>, fname) <span class="cf">for</span> fname <span class="kw">in</span> os.listdir(train_dir <span class="op">+</span> <span class="st">'/cats'</span>)[idx:idx<span class="op">+</span><span class="dv">8</span>]]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>next_dog_pix <span class="op">=</span> [os.path.join(train_dir <span class="op">+</span> <span class="st">'/dogs'</span>, fname) <span class="cf">for</span> fname <span class="kw">in</span> os.listdir(train_dir <span class="op">+</span> <span class="st">'/dogs'</span>)[idx:idx<span class="op">+</span><span class="dv">8</span>]]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, img_path <span class="kw">in</span> <span class="bu">enumerate</span>(next_cat_pix<span class="op">+</span>next_dog_pix):</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set up subplot; subplot indices start at 1</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> plt.subplot(<span class="dv">4</span>, <span class="dv">4</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  ax.axis(<span class="st">'Off'</span>) <span class="co"># Don't show axes (or gridlines)</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  img <span class="op">=</span> mpimg.imread(img_path)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  plt.imshow(img)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In order to train a binary classifier on this data, we would need to load the images and transform them into Numpy arrays that can be passed to tensorflow. Fortunately, keras provides an utility to do it automatically: <code>ImageDataGenerator</code>. Doc:</p>
<p><a href="https://keras.io/api/preprocessing/image/" class="uri">https://keras.io/api/preprocessing/image/</a></p>
<p>The procedure is to create an <code>ImageDataGenerator</code> instance and to create an <strong>iterator</strong> with <code>flow_from_directory</code> that will return minibatches on demand when training the neural network. The main advantage of this approach is that you do not need to load the whole dataset in the RAM (not possible for most realistic datasets), but adds an overhead between each minibatch.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> datagen.flow_from_directory(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        directory,  <span class="co"># This is the source directory for training images</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        target_size<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>),  <span class="co"># All images will be resized to 150x150</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Since we use binary_crossentropy loss, we need binary labels</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        class_mode<span class="op">=</span><span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>rescale</code> argument makes sure that the pixels will be represented by float values between 0 and 1, not integers between 0 and 255. Unfortunately, it is not possible (or very hard) to perform mean-removal using this method. The image data generator accepts additional arguments that we will discuss in the section on data augmentation. <code>directory</code> must be set to the folder containing the images. We ask the generator to resize all images to 150x150 and will use a batch size of 64. As there are only two classes cat and dog, the labels will be binary (0 and 1).</p>
<p><strong>Q:</strong> Create two generators <code>train_generator</code> and <code>validation_generator</code> for the training and validation sets respectively, with a batch size of 64.</p>
<div class="cell" data-outputid="5b703fc2-f903-4db8-8f37-e7106862bed3" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All images will be rescaled by 1./255</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>train_datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>val_datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Flow training images in batches </span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>train_generator <span class="op">=</span> train_datagen.flow_from_directory(</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        train_dir,  </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        target_size<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>),  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        class_mode<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Flow validation images in batches</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>validation_generator <span class="op">=</span> val_datagen.flow_from_directory(</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        validation_dir,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        target_size<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>),</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        class_mode<span class="op">=</span><span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.</code></pre>
</div>
</div>
<p><strong>Q:</strong> Sample a minibatch from the training generator by calling <code>next()</code> on it (<code>X, t = train_generator.next()</code>) and display the first image. Call the cell multiple times.</p>
<div class="cell" data-outputid="7833d3ea-a0a0-4f0e-9228-d24d7b85f6f8" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X, t <span class="op">=</span> train_generator.<span class="bu">next</span>()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(X[<span class="dv">0</span>, :, :, :])</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"Off"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(64, 150, 150, 3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="functional-api-of-keras" class="level2">
<h2 class="anchored" data-anchor-id="functional-api-of-keras">Functional API of Keras</h2>
<p>In the previous exercises, we used the Sequential API of keras, which stacks layers on top of each other:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.Input((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.Flatten())</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this exercise, we will use the Functional API of keras, which gives much more freedom to the programmer. The main difference is that you can explicitly specify from which layer a layer should take its inputs:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tf.keras.layers.Input((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Flatten()(x)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Model(inputs, outputs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This allows to create complex architectures, for examples with several output layers.</p>
<p><strong>Q:</strong> Modify your CNN of last exercise so that it is defined with the Functional API and train it on MNIST.</p>
<div class="cell" data-outputid="066c465a-d3af-4f0b-e289-7b7628096773" data-execution_count="7">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fetch the MNIST data</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>(X_train, t_train), (X_test, t_test) <span class="op">=</span> tf.keras.datasets.mnist.load_data()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training data:"</span>, X_train.shape, t_train.shape)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test data:"</span>, X_test.shape, t_test.shape)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize the values</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>).astype(<span class="st">'float32'</span>) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>).astype(<span class="st">'float32'</span>) <span class="op">/</span> <span class="fl">255.</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean removal</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>X_mean <span class="op">=</span> np.mean(X_train, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">-=</span> X_mean</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">-=</span> X_mean</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encoding</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>T_train <span class="op">=</span> tf.keras.utils.to_categorical(t_train, <span class="dv">10</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>T_test <span class="op">=</span> tf.keras.utils.to_categorical(t_test, <span class="dv">10</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Delete all previous models to free memory</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Functional model</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tf.keras.layers.Input((<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'valid'</span>)(inputs)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.5</span>)(x)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">'relu'</span>, padding<span class="op">=</span><span class="st">'valid'</span>)(x)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.5</span>)(x)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Flatten()(x)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">150</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.5</span>)(x)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Model(inputs, outputs)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rule</span></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> tf.keras.optimizers.SGD(learning_rate<span class="op">=</span><span class="fl">0.01</span>, decay<span class="op">=</span><span class="fl">1e-6</span>, momentum<span class="op">=</span><span class="fl">0.9</span>, nesterov<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Loss function</span></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, <span class="co"># loss</span></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer, <span class="co"># learning rule</span></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>] <span class="co"># show accuracy</span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> tf.keras.callbacks.History()</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>    X_train, T_train,</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>, </span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[history]</span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test, T_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test loss:'</span>, score[<span class="dv">0</span>])</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Test accuracy:'</span>, score[<span class="dv">1</span>])</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'accuracy'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_accuracy'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training data: (60000, 28, 28) (60000,)
Test data: (10000, 28, 28) (10000,)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:30:50.851406: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-11-15 10:30:50.851519: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Metal device set to: Apple M1 Pro

systemMemory: 16.00 GB
maxCacheSize: 5.33 GB

Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 28, 28, 1)]       0         
                                                                 
 conv2d (Conv2D)             (None, 26, 26, 32)        320       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 13, 13, 32)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 5, 5, 64)          0         
                                                                 
 flatten (Flatten)           (None, 1600)              0         
                                                                 
 dense (Dense)               (None, 150)               240150    
                                                                 
 dropout_2 (Dropout)         (None, 150)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                1510      
                                                                 
=================================================================
Total params: 260,476
Trainable params: 260,476
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:30:51.651254: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-11-15 10:30:51.888660: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>844/844 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8523</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:31:08.543351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>844/844 [==============================] - 18s 17ms/step - loss: 0.4516 - accuracy: 0.8523 - val_loss: 0.0851 - val_accuracy: 0.9770
Epoch 2/20
844/844 [==============================] - 14s 17ms/step - loss: 0.1421 - accuracy: 0.9561 - val_loss: 0.0598 - val_accuracy: 0.9837
Epoch 3/20
844/844 [==============================] - 13s 16ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.0517 - val_accuracy: 0.9858
Epoch 4/20
844/844 [==============================] - 13s 16ms/step - loss: 0.0914 - accuracy: 0.9725 - val_loss: 0.0498 - val_accuracy: 0.9853
Epoch 5/20
844/844 [==============================] - 14s 16ms/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.0413 - val_accuracy: 0.9873
Epoch 6/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0718 - accuracy: 0.9773 - val_loss: 0.0385 - val_accuracy: 0.9892
Epoch 7/20
844/844 [==============================] - 13s 16ms/step - loss: 0.0659 - accuracy: 0.9793 - val_loss: 0.0346 - val_accuracy: 0.9900
Epoch 8/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.0328 - val_accuracy: 0.9910
Epoch 9/20
844/844 [==============================] - 13s 16ms/step - loss: 0.0579 - accuracy: 0.9820 - val_loss: 0.0325 - val_accuracy: 0.9907
Epoch 10/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.0329 - val_accuracy: 0.9905
Epoch 11/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0526 - accuracy: 0.9835 - val_loss: 0.0323 - val_accuracy: 0.9908
Epoch 12/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.0303 - val_accuracy: 0.9913
Epoch 13/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.0305 - val_accuracy: 0.9902
Epoch 14/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0475 - accuracy: 0.9859 - val_loss: 0.0308 - val_accuracy: 0.9908
Epoch 15/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.0329 - val_accuracy: 0.9908
Epoch 16/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0292 - val_accuracy: 0.9912
Epoch 17/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.0303 - val_accuracy: 0.9915
Epoch 18/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.0288 - val_accuracy: 0.9923
Epoch 19/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.0274 - val_accuracy: 0.9925
Epoch 20/20
844/844 [==============================] - 13s 15ms/step - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.0269 - val_accuracy: 0.9915
Test loss: 0.022337375208735466
Test accuracy: 0.9923000335693359</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-8-output-8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-a-cnn-from-scratch" class="level2">
<h2 class="anchored" data-anchor-id="training-a-cnn-from-scratch">Training a CNN from scratch</h2>
<p>Let’s now train a randomly-initialized CNN on the dog vs.&nbsp;cat data. You are free to choose any architecture you like, the only requirements are:</p>
<ul>
<li>The input image must be 150x150x3:</li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>tf.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>The output neuron must use the logistic/sigmoid activation function (binary classification:</li>
</ul>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>The loss function must be <code>'binary_crossentropy'</code> and the metric <code>binary_accuracy</code>:</li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>              optimizer<span class="op">=</span>optimizer,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>              metrics<span class="op">=</span>[<span class="st">'binary_accuracy'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There is not a lot of data, so you can safely go deep with your architecture (i.e.&nbsp;with convolutional layers and max-pooling until the image dimensions are around 7x7), especially if you use the GPU on Colab.</p>
<p>To train and validate the network on the generators, just pass them to <code>model.fit()</code>:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>      train_generator,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>      epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>      validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>      callbacks<span class="op">=</span>[history])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Design a CNN and train it on the data for 30 epochs. A final validation accuracy around 72% - 75% is already good, you can then go to the next question.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_model():</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Delete all previous models to free memory</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    tf.keras.backend.clear_session()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the three color channels: R, G, and B</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First convolution extracts 16 filters that are 3x3</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convolution is followed by max-pooling layer with a 2x2 window</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">16</span>, <span class="dv">3</span>)(inputs)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Activation(<span class="st">"relu"</span>)(x)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.MaxPooling2D(<span class="dv">2</span>)(x)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Second convolution extracts 32 filters that are 3x3</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convolution is followed by max-pooling layer with a 2x2 window</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">32</span>, <span class="dv">3</span>)(x)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Activation(<span class="st">"relu"</span>)(x)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.MaxPooling2D(<span class="dv">2</span>)(x)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Third convolution extracts 64 filters that are 3x3</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convolution is followed by max-pooling layer with a 2x2 window</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">64</span>, <span class="dv">3</span>)(x)</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Activation(<span class="st">"relu"</span>)(x)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.MaxPooling2D(<span class="dv">2</span>)(x)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fourth convolution extracts 64 filters that are 3x3</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convolution is followed by max-pooling layer with a 2x2 window</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Conv2D(<span class="dv">64</span>, <span class="dv">3</span>)(x)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Activation(<span class="st">"relu"</span>)(x)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.MaxPooling2D(<span class="dv">2</span>)(x)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten feature map to a 1-dim tensor so we can add fully connected layers</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Flatten()(x)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a fully connected layer with ReLU activation and 512 hidden units</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create output layer with a single node and sigmoid activation</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(x)</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model:</span></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># input = input feature map</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># output = input feature map + stacked convolution/maxpooling layers + fully </span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># connected layer + sigmoid output layer</span></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Model(inputs, outputs)</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compile model for binary classification</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>                optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0005</span>),</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>                metrics<span class="op">=</span>[<span class="st">'binary_accuracy'</span>])</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(model.summary())</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="9debe60b-632c-4bca-cdba-b9b037dd1468" data-execution_count="9">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> random_model()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> tf.keras.callbacks.History()</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>      train_generator,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>      epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>      validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>      callbacks<span class="op">=</span>[history])</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'binary_accuracy'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_binary_accuracy'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 150, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 148, 148, 16)      448       
                                                                 
 activation (Activation)     (None, 148, 148, 16)      0         
                                                                 
 max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 74, 74, 16)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      
                                                                 
 activation_1 (Activation)   (None, 72, 72, 32)        0         
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 36, 36, 32)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     
                                                                 
 activation_2 (Activation)   (None, 34, 34, 64)        0         
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 17, 17, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     
                                                                 
 activation_3 (Activation)   (None, 15, 15, 64)        0         
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 dropout_3 (Dropout)         (None, 7, 7, 64)          0         
                                                                 
 flatten (Flatten)           (None, 3136)              0         
                                                                 
 dense (Dense)               (None, 512)               1606144   
                                                                 
 dropout_4 (Dropout)         (None, 512)               0         
                                                                 
 dense_1 (Dense)             (None, 1)                 513       
                                                                 
=================================================================
Total params: 1,667,169
Trainable params: 1,667,169
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/30</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:35:37.036309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - ETA: 0s - loss: 0.7086 - binary_accuracy: 0.5200</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:35:42.569436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - 8s 170ms/step - loss: 0.7086 - binary_accuracy: 0.5200 - val_loss: 0.6926 - val_binary_accuracy: 0.5100
Epoch 2/30
32/32 [==============================] - 4s 134ms/step - loss: 0.6920 - binary_accuracy: 0.5240 - val_loss: 0.6893 - val_binary_accuracy: 0.5560
Epoch 3/30
32/32 [==============================] - 4s 126ms/step - loss: 0.6926 - binary_accuracy: 0.5100 - val_loss: 0.6926 - val_binary_accuracy: 0.5000
Epoch 4/30
32/32 [==============================] - 4s 127ms/step - loss: 0.6837 - binary_accuracy: 0.5505 - val_loss: 0.6865 - val_binary_accuracy: 0.5550
Epoch 5/30
32/32 [==============================] - 4s 128ms/step - loss: 0.6594 - binary_accuracy: 0.5990 - val_loss: 0.6629 - val_binary_accuracy: 0.6010
Epoch 6/30
32/32 [==============================] - 4s 129ms/step - loss: 0.6442 - binary_accuracy: 0.6170 - val_loss: 0.6575 - val_binary_accuracy: 0.6000
Epoch 7/30
32/32 [==============================] - 4s 138ms/step - loss: 0.6057 - binary_accuracy: 0.6555 - val_loss: 0.6330 - val_binary_accuracy: 0.6100
Epoch 8/30
32/32 [==============================] - 4s 131ms/step - loss: 0.5850 - binary_accuracy: 0.6940 - val_loss: 0.6408 - val_binary_accuracy: 0.6100
Epoch 9/30
32/32 [==============================] - 4s 127ms/step - loss: 0.5491 - binary_accuracy: 0.7150 - val_loss: 0.6049 - val_binary_accuracy: 0.6550
Epoch 10/30
32/32 [==============================] - 4s 123ms/step - loss: 0.5261 - binary_accuracy: 0.7330 - val_loss: 0.5941 - val_binary_accuracy: 0.6720
Epoch 11/30
32/32 [==============================] - 4s 134ms/step - loss: 0.5159 - binary_accuracy: 0.7370 - val_loss: 0.5622 - val_binary_accuracy: 0.6960
Epoch 12/30
32/32 [==============================] - 4s 130ms/step - loss: 0.4882 - binary_accuracy: 0.7560 - val_loss: 0.5616 - val_binary_accuracy: 0.6980
Epoch 13/30
32/32 [==============================] - 4s 133ms/step - loss: 0.4752 - binary_accuracy: 0.7755 - val_loss: 0.5695 - val_binary_accuracy: 0.6820
Epoch 14/30
32/32 [==============================] - 4s 123ms/step - loss: 0.4569 - binary_accuracy: 0.7865 - val_loss: 0.6656 - val_binary_accuracy: 0.6430
Epoch 15/30
32/32 [==============================] - 4s 123ms/step - loss: 0.4456 - binary_accuracy: 0.7885 - val_loss: 0.6187 - val_binary_accuracy: 0.6720
Epoch 16/30
32/32 [==============================] - 4s 122ms/step - loss: 0.4379 - binary_accuracy: 0.7870 - val_loss: 0.5857 - val_binary_accuracy: 0.6860
Epoch 17/30
32/32 [==============================] - 4s 123ms/step - loss: 0.3996 - binary_accuracy: 0.8130 - val_loss: 0.5482 - val_binary_accuracy: 0.7070
Epoch 18/30
32/32 [==============================] - 4s 123ms/step - loss: 0.3852 - binary_accuracy: 0.8290 - val_loss: 0.5514 - val_binary_accuracy: 0.7250
Epoch 19/30
32/32 [==============================] - 4s 124ms/step - loss: 0.3729 - binary_accuracy: 0.8320 - val_loss: 0.5720 - val_binary_accuracy: 0.7100
Epoch 20/30
32/32 [==============================] - 4s 123ms/step - loss: 0.3229 - binary_accuracy: 0.8515 - val_loss: 0.5621 - val_binary_accuracy: 0.7310
Epoch 21/30
32/32 [==============================] - 4s 125ms/step - loss: 0.3205 - binary_accuracy: 0.8560 - val_loss: 0.6413 - val_binary_accuracy: 0.6870
Epoch 22/30
32/32 [==============================] - 4s 123ms/step - loss: 0.2989 - binary_accuracy: 0.8635 - val_loss: 0.5969 - val_binary_accuracy: 0.7190
Epoch 23/30
32/32 [==============================] - 4s 125ms/step - loss: 0.2685 - binary_accuracy: 0.8870 - val_loss: 0.5636 - val_binary_accuracy: 0.7370
Epoch 24/30
32/32 [==============================] - 4s 123ms/step - loss: 0.2532 - binary_accuracy: 0.8925 - val_loss: 0.5702 - val_binary_accuracy: 0.7310
Epoch 25/30
32/32 [==============================] - 4s 123ms/step - loss: 0.2554 - binary_accuracy: 0.8980 - val_loss: 0.5543 - val_binary_accuracy: 0.7420
Epoch 26/30
32/32 [==============================] - 4s 123ms/step - loss: 0.2184 - binary_accuracy: 0.9155 - val_loss: 0.5953 - val_binary_accuracy: 0.7370
Epoch 27/30
32/32 [==============================] - 4s 126ms/step - loss: 0.1950 - binary_accuracy: 0.9195 - val_loss: 0.6326 - val_binary_accuracy: 0.7410
Epoch 28/30
32/32 [==============================] - 4s 127ms/step - loss: 0.1646 - binary_accuracy: 0.9335 - val_loss: 0.6373 - val_binary_accuracy: 0.7480
Epoch 29/30
32/32 [==============================] - 4s 123ms/step - loss: 0.1419 - binary_accuracy: 0.9495 - val_loss: 0.6665 - val_binary_accuracy: 0.7430
Epoch 30/30
32/32 [==============================] - 4s 124ms/step - loss: 0.1276 - binary_accuracy: 0.9535 - val_loss: 0.6939 - val_binary_accuracy: 0.7400</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-10-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> There is no unique solution, but it is very difficult to avoid overfitting with such a low amount of data. The validation accuracy saturates between 70% and 75% while the training accuracy reaches 100% if you train for more epochs.</p>
</section>
<section id="data-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation">Data augmentation</h2>
<p>The 2000 training images will never be enough to train a CNN from scratch without overfitting, no matter how much regularization you use. A first trick that may help is <strong>data augmentation</strong>, i.e.&nbsp;to artificially create variations of each training image (translation, rotation, scaling, flipping, etc) while preserving the class of the images (a cat stays a cat after rotating the image).</p>
<p><code>ImageDataGenerator</code> allows to automatically apply various transformations when retrieving a minibatch (beware, it can be slow).</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    rotation_range<span class="op">=</span><span class="dv">40</span>,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    width_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    height_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    shear_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    zoom_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    horizontal_flip<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    fill_mode<span class="op">=</span><span class="st">'nearest'</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Refer the doc for the meaning of the parameters.</p>
<p>To investigate the transformations, let’s apply them on a single image, for example the first cat of the training set:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> tf.keras.preprocessing.image.load_img(<span class="st">'/tmp/cats_and_dogs_filtered/train/cats/cat.0.jpg'</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> tf.keras.preprocessing.image.img_to_array(img)  </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.reshape((<span class="dv">1</span>,) <span class="op">+</span> img.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can pass this image to the data generator and retrieve minibatches of augmented images:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> datagen.flow(img, batch_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>augmented <span class="op">=</span> generator.<span class="bu">next</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Display various augmented images. Vary the parameters individually by setting all but one to their default value in order to understand their effect.</p>
<div class="cell" data-outputid="9d6a3ebf-4655-45ea-b1b5-0a255f2432d9" data-execution_count="10">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>test_datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>,</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    rotation_range<span class="op">=</span><span class="dv">40</span>,</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    width_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    height_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    shear_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    zoom_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    horizontal_flip<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    fill_mode<span class="op">=</span><span class="st">'nearest'</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> tf.keras.preprocessing.image.load_img(<span class="st">'/tmp/cats_and_dogs_filtered/train/cats/cat.0.jpg'</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> tf.keras.preprocessing.image.img_to_array(img)  </span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.reshape((<span class="dv">1</span>,) <span class="op">+</span> img.shape)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>test_generator <span class="op">=</span> test_datagen.flow(img, batch_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>augmented <span class="op">=</span> test_generator.<span class="bu">next</span>()</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>plt.imshow(img[<span class="dv">0</span>, :, :, :]<span class="op">/</span><span class="fl">255.</span>)</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"Off"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original"</span>)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>plt.imshow(augmented[<span class="dv">0</span>, :, :, :])</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"Off"</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Augmented"</span>)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Q:</strong> Create an augmented training set using the parameters defined in the previous question (feel free to experiment, but that can cost time). Leave the validation generator without data augmentation (only <code>rescale=1./255</code>). Train the exact same network as before on this augmented data. What happens? You may need to train much longer in order to see the effect.</p>
<div class="cell" data-outputid="cca6bfb7-517e-4281-d64d-815ce939ead6" data-execution_count="11">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data augmentation</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>augmented_train_datagen <span class="op">=</span> tf.keras.preprocessing.image.ImageDataGenerator(</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    rescale<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">255</span>,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    rotation_range<span class="op">=</span><span class="dv">40</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    width_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    height_shift_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    shear_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    zoom_range<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    horizontal_flip<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    fill_mode<span class="op">=</span><span class="st">'nearest'</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Flow training images in batches of 20 using train_datagen generator</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>augmented_train_generator <span class="op">=</span> augmented_train_datagen.flow_from_directory(</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        train_dir, </span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        target_size<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>),  </span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        class_mode<span class="op">=</span><span class="st">'binary'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 2000 images belonging to 2 classes.</code></pre>
</div>
</div>
<div class="cell" data-outputid="3f7ba833-2a2c-4148-e9ca-b61c6f094155" data-execution_count="12">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> random_model()</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> tf.keras.callbacks.History()</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>      augmented_train_generator,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>      epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>      validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>      callbacks<span class="op">=</span>[history])</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'binary_accuracy'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_binary_accuracy'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 150, 3)]     0         
                                                                 
 conv2d (Conv2D)             (None, 148, 148, 16)      448       
                                                                 
 activation (Activation)     (None, 148, 148, 16)      0         
                                                                 
 max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 74, 74, 16)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      
                                                                 
 activation_1 (Activation)   (None, 72, 72, 32)        0         
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 36, 36, 32)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     
                                                                 
 activation_2 (Activation)   (None, 34, 34, 64)        0         
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 17, 17, 64)        0         
                                                                 
 conv2d_3 (Conv2D)           (None, 15, 15, 64)        36928     
                                                                 
 activation_3 (Activation)   (None, 15, 15, 64)        0         
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 dropout_3 (Dropout)         (None, 7, 7, 64)          0         
                                                                 
 flatten (Flatten)           (None, 3136)              0         
                                                                 
 dense (Dense)               (None, 512)               1606144   
                                                                 
 dropout_4 (Dropout)         (None, 512)               0         
                                                                 
 dense_1 (Dense)             (None, 1)                 513       
                                                                 
=================================================================
Total params: 1,667,169
Trainable params: 1,667,169
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:37:55.950584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - ETA: 0s - loss: 0.6987 - binary_accuracy: 0.5190</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 10:38:03.512980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - 9s 276ms/step - loss: 0.6987 - binary_accuracy: 0.5190 - val_loss: 0.6914 - val_binary_accuracy: 0.5920
Epoch 2/100
32/32 [==============================] - 9s 275ms/step - loss: 0.6870 - binary_accuracy: 0.5295 - val_loss: 0.6747 - val_binary_accuracy: 0.5940
Epoch 3/100
32/32 [==============================] - 9s 273ms/step - loss: 0.6677 - binary_accuracy: 0.5645 - val_loss: 0.6702 - val_binary_accuracy: 0.5680
Epoch 4/100
32/32 [==============================] - 9s 270ms/step - loss: 0.6601 - binary_accuracy: 0.6015 - val_loss: 0.6424 - val_binary_accuracy: 0.6300
Epoch 5/100
32/32 [==============================] - 9s 276ms/step - loss: 0.6520 - binary_accuracy: 0.5960 - val_loss: 0.6468 - val_binary_accuracy: 0.6030
Epoch 6/100
32/32 [==============================] - 9s 268ms/step - loss: 0.6399 - binary_accuracy: 0.6325 - val_loss: 0.6120 - val_binary_accuracy: 0.6630
Epoch 7/100
32/32 [==============================] - 8s 265ms/step - loss: 0.6410 - binary_accuracy: 0.6170 - val_loss: 0.6188 - val_binary_accuracy: 0.6490
Epoch 8/100
32/32 [==============================] - 9s 271ms/step - loss: 0.6234 - binary_accuracy: 0.6585 - val_loss: 0.6012 - val_binary_accuracy: 0.6530
Epoch 9/100
32/32 [==============================] - 9s 268ms/step - loss: 0.6183 - binary_accuracy: 0.6540 - val_loss: 0.6085 - val_binary_accuracy: 0.6480
Epoch 10/100
32/32 [==============================] - 9s 270ms/step - loss: 0.6095 - binary_accuracy: 0.6510 - val_loss: 0.6147 - val_binary_accuracy: 0.6450
Epoch 11/100
32/32 [==============================] - 9s 267ms/step - loss: 0.6000 - binary_accuracy: 0.6600 - val_loss: 0.6377 - val_binary_accuracy: 0.6330
Epoch 12/100
32/32 [==============================] - 8s 262ms/step - loss: 0.6090 - binary_accuracy: 0.6575 - val_loss: 0.6048 - val_binary_accuracy: 0.6510
Epoch 13/100
32/32 [==============================] - 9s 268ms/step - loss: 0.5895 - binary_accuracy: 0.6760 - val_loss: 0.5961 - val_binary_accuracy: 0.6740
Epoch 14/100
32/32 [==============================] - 8s 264ms/step - loss: 0.5822 - binary_accuracy: 0.6835 - val_loss: 0.6069 - val_binary_accuracy: 0.6560
Epoch 15/100
32/32 [==============================] - 9s 266ms/step - loss: 0.5749 - binary_accuracy: 0.7015 - val_loss: 0.5993 - val_binary_accuracy: 0.6740
Epoch 16/100
32/32 [==============================] - 9s 267ms/step - loss: 0.5894 - binary_accuracy: 0.6765 - val_loss: 0.5944 - val_binary_accuracy: 0.6620
Epoch 17/100
32/32 [==============================] - 8s 265ms/step - loss: 0.5900 - binary_accuracy: 0.6705 - val_loss: 0.5792 - val_binary_accuracy: 0.6860
Epoch 18/100
32/32 [==============================] - 8s 265ms/step - loss: 0.5741 - binary_accuracy: 0.6885 - val_loss: 0.6015 - val_binary_accuracy: 0.6640
Epoch 19/100
32/32 [==============================] - 8s 260ms/step - loss: 0.5642 - binary_accuracy: 0.7045 - val_loss: 0.5731 - val_binary_accuracy: 0.7000
Epoch 20/100
32/32 [==============================] - 8s 264ms/step - loss: 0.5609 - binary_accuracy: 0.7025 - val_loss: 0.6254 - val_binary_accuracy: 0.6730
Epoch 21/100
32/32 [==============================] - 8s 260ms/step - loss: 0.5781 - binary_accuracy: 0.7020 - val_loss: 0.5878 - val_binary_accuracy: 0.6860
Epoch 22/100
32/32 [==============================] - 8s 257ms/step - loss: 0.5531 - binary_accuracy: 0.7020 - val_loss: 0.5665 - val_binary_accuracy: 0.7120
Epoch 23/100
32/32 [==============================] - 8s 259ms/step - loss: 0.5498 - binary_accuracy: 0.7170 - val_loss: 0.5854 - val_binary_accuracy: 0.6870
Epoch 24/100
32/32 [==============================] - 8s 262ms/step - loss: 0.5519 - binary_accuracy: 0.7105 - val_loss: 0.5744 - val_binary_accuracy: 0.6960
Epoch 25/100
32/32 [==============================] - 8s 262ms/step - loss: 0.5455 - binary_accuracy: 0.7210 - val_loss: 0.6396 - val_binary_accuracy: 0.6670
Epoch 26/100
32/32 [==============================] - 8s 258ms/step - loss: 0.5536 - binary_accuracy: 0.7110 - val_loss: 0.5603 - val_binary_accuracy: 0.6920
Epoch 27/100
32/32 [==============================] - 8s 258ms/step - loss: 0.5476 - binary_accuracy: 0.7175 - val_loss: 0.6090 - val_binary_accuracy: 0.6820
Epoch 28/100
32/32 [==============================] - 8s 259ms/step - loss: 0.5404 - binary_accuracy: 0.7225 - val_loss: 0.5681 - val_binary_accuracy: 0.7130
Epoch 29/100
32/32 [==============================] - 8s 258ms/step - loss: 0.5247 - binary_accuracy: 0.7335 - val_loss: 0.6184 - val_binary_accuracy: 0.6640
Epoch 30/100
32/32 [==============================] - 8s 257ms/step - loss: 0.5264 - binary_accuracy: 0.7450 - val_loss: 0.5810 - val_binary_accuracy: 0.7010
Epoch 31/100
32/32 [==============================] - 8s 260ms/step - loss: 0.5124 - binary_accuracy: 0.7495 - val_loss: 0.6055 - val_binary_accuracy: 0.6810
Epoch 32/100
32/32 [==============================] - 8s 265ms/step - loss: 0.5537 - binary_accuracy: 0.7085 - val_loss: 0.5449 - val_binary_accuracy: 0.7130
Epoch 33/100
32/32 [==============================] - 9s 266ms/step - loss: 0.5221 - binary_accuracy: 0.7445 - val_loss: 0.6216 - val_binary_accuracy: 0.6520
Epoch 34/100
32/32 [==============================] - 8s 262ms/step - loss: 0.5175 - binary_accuracy: 0.7400 - val_loss: 0.5457 - val_binary_accuracy: 0.7080
Epoch 35/100
32/32 [==============================] - 9s 264ms/step - loss: 0.5224 - binary_accuracy: 0.7430 - val_loss: 0.5182 - val_binary_accuracy: 0.7410
Epoch 36/100
32/32 [==============================] - 9s 266ms/step - loss: 0.5141 - binary_accuracy: 0.7435 - val_loss: 0.5616 - val_binary_accuracy: 0.7000
Epoch 37/100
32/32 [==============================] - 9s 269ms/step - loss: 0.5052 - binary_accuracy: 0.7520 - val_loss: 0.5460 - val_binary_accuracy: 0.7200
Epoch 38/100
32/32 [==============================] - 110s 4s/step - loss: 0.5164 - binary_accuracy: 0.7485 - val_loss: 0.6408 - val_binary_accuracy: 0.6360
Epoch 39/100
32/32 [==============================] - 8s 252ms/step - loss: 0.5176 - binary_accuracy: 0.7415 - val_loss: 0.6007 - val_binary_accuracy: 0.6900
Epoch 40/100
32/32 [==============================] - 8s 250ms/step - loss: 0.5006 - binary_accuracy: 0.7545 - val_loss: 0.5449 - val_binary_accuracy: 0.7070
Epoch 41/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4983 - binary_accuracy: 0.7655 - val_loss: 0.5754 - val_binary_accuracy: 0.6920
Epoch 42/100
32/32 [==============================] - 8s 257ms/step - loss: 0.4989 - binary_accuracy: 0.7565 - val_loss: 0.5492 - val_binary_accuracy: 0.7220
Epoch 43/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4948 - binary_accuracy: 0.7620 - val_loss: 0.5719 - val_binary_accuracy: 0.7140
Epoch 44/100
32/32 [==============================] - 8s 249ms/step - loss: 0.4802 - binary_accuracy: 0.7655 - val_loss: 0.6214 - val_binary_accuracy: 0.7000
Epoch 45/100
32/32 [==============================] - 8s 246ms/step - loss: 0.4960 - binary_accuracy: 0.7595 - val_loss: 0.5552 - val_binary_accuracy: 0.7130
Epoch 46/100
32/32 [==============================] - 8s 248ms/step - loss: 0.4943 - binary_accuracy: 0.7600 - val_loss: 0.5689 - val_binary_accuracy: 0.7110
Epoch 47/100
32/32 [==============================] - 9s 275ms/step - loss: 0.4898 - binary_accuracy: 0.7560 - val_loss: 0.6013 - val_binary_accuracy: 0.7090
Epoch 48/100
32/32 [==============================] - 11s 342ms/step - loss: 0.4824 - binary_accuracy: 0.7690 - val_loss: 0.4911 - val_binary_accuracy: 0.7610
Epoch 49/100
32/32 [==============================] - 10s 309ms/step - loss: 0.4827 - binary_accuracy: 0.7635 - val_loss: 0.5036 - val_binary_accuracy: 0.7410
Epoch 50/100
32/32 [==============================] - 10s 312ms/step - loss: 0.4741 - binary_accuracy: 0.7620 - val_loss: 0.5096 - val_binary_accuracy: 0.7430
Epoch 51/100
32/32 [==============================] - 10s 296ms/step - loss: 0.4653 - binary_accuracy: 0.7810 - val_loss: 0.5334 - val_binary_accuracy: 0.7310
Epoch 52/100
32/32 [==============================] - 9s 294ms/step - loss: 0.4807 - binary_accuracy: 0.7645 - val_loss: 0.5092 - val_binary_accuracy: 0.7490
Epoch 53/100
32/32 [==============================] - 10s 304ms/step - loss: 0.4642 - binary_accuracy: 0.7790 - val_loss: 0.5362 - val_binary_accuracy: 0.7410
Epoch 54/100
32/32 [==============================] - 9s 275ms/step - loss: 0.4573 - binary_accuracy: 0.7815 - val_loss: 0.5207 - val_binary_accuracy: 0.7300
Epoch 55/100
32/32 [==============================] - 8s 261ms/step - loss: 0.4654 - binary_accuracy: 0.7795 - val_loss: 0.5284 - val_binary_accuracy: 0.7420
Epoch 56/100
32/32 [==============================] - 8s 255ms/step - loss: 0.4572 - binary_accuracy: 0.7785 - val_loss: 0.5014 - val_binary_accuracy: 0.7430
Epoch 57/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4654 - binary_accuracy: 0.7750 - val_loss: 0.4811 - val_binary_accuracy: 0.7670
Epoch 58/100
32/32 [==============================] - 8s 249ms/step - loss: 0.4480 - binary_accuracy: 0.7925 - val_loss: 0.5795 - val_binary_accuracy: 0.7120
Epoch 59/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4503 - binary_accuracy: 0.7805 - val_loss: 0.5151 - val_binary_accuracy: 0.7440
Epoch 60/100
32/32 [==============================] - 8s 252ms/step - loss: 0.4572 - binary_accuracy: 0.7890 - val_loss: 0.5013 - val_binary_accuracy: 0.7500
Epoch 61/100
32/32 [==============================] - 9s 268ms/step - loss: 0.4552 - binary_accuracy: 0.7775 - val_loss: 0.5036 - val_binary_accuracy: 0.7500
Epoch 62/100
32/32 [==============================] - 9s 266ms/step - loss: 0.4418 - binary_accuracy: 0.7920 - val_loss: 0.5908 - val_binary_accuracy: 0.7110
Epoch 63/100
32/32 [==============================] - 9s 268ms/step - loss: 0.4342 - binary_accuracy: 0.7960 - val_loss: 0.5061 - val_binary_accuracy: 0.7590
Epoch 64/100
32/32 [==============================] - 8s 264ms/step - loss: 0.4471 - binary_accuracy: 0.7865 - val_loss: 0.4961 - val_binary_accuracy: 0.7550
Epoch 65/100
32/32 [==============================] - 9s 266ms/step - loss: 0.4494 - binary_accuracy: 0.7900 - val_loss: 0.5424 - val_binary_accuracy: 0.7320
Epoch 66/100
32/32 [==============================] - 9s 265ms/step - loss: 0.4257 - binary_accuracy: 0.7995 - val_loss: 0.5377 - val_binary_accuracy: 0.7520
Epoch 67/100
32/32 [==============================] - 8s 261ms/step - loss: 0.4504 - binary_accuracy: 0.7815 - val_loss: 0.6068 - val_binary_accuracy: 0.7150
Epoch 68/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4275 - binary_accuracy: 0.8045 - val_loss: 0.4592 - val_binary_accuracy: 0.7720
Epoch 69/100
32/32 [==============================] - 8s 248ms/step - loss: 0.4429 - binary_accuracy: 0.7850 - val_loss: 0.4845 - val_binary_accuracy: 0.7550
Epoch 70/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4171 - binary_accuracy: 0.8040 - val_loss: 0.6250 - val_binary_accuracy: 0.7110
Epoch 71/100
32/32 [==============================] - 8s 252ms/step - loss: 0.4440 - binary_accuracy: 0.7875 - val_loss: 0.5684 - val_binary_accuracy: 0.7190
Epoch 72/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4044 - binary_accuracy: 0.8105 - val_loss: 0.4783 - val_binary_accuracy: 0.7740
Epoch 73/100
32/32 [==============================] - 8s 254ms/step - loss: 0.4366 - binary_accuracy: 0.7935 - val_loss: 0.4487 - val_binary_accuracy: 0.7840
Epoch 74/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4385 - binary_accuracy: 0.7900 - val_loss: 0.4717 - val_binary_accuracy: 0.7630
Epoch 75/100
32/32 [==============================] - 8s 252ms/step - loss: 0.4435 - binary_accuracy: 0.7900 - val_loss: 0.4625 - val_binary_accuracy: 0.7830
Epoch 76/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4228 - binary_accuracy: 0.8010 - val_loss: 0.5609 - val_binary_accuracy: 0.7120
Epoch 77/100
32/32 [==============================] - 8s 254ms/step - loss: 0.4428 - binary_accuracy: 0.7860 - val_loss: 0.4750 - val_binary_accuracy: 0.7720
Epoch 78/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4294 - binary_accuracy: 0.7920 - val_loss: 0.4582 - val_binary_accuracy: 0.7770
Epoch 79/100
32/32 [==============================] - 8s 251ms/step - loss: 0.4172 - binary_accuracy: 0.7985 - val_loss: 0.5194 - val_binary_accuracy: 0.7460
Epoch 80/100
32/32 [==============================] - 8s 252ms/step - loss: 0.4132 - binary_accuracy: 0.8075 - val_loss: 0.5521 - val_binary_accuracy: 0.7350
Epoch 81/100
32/32 [==============================] - 8s 251ms/step - loss: 0.4329 - binary_accuracy: 0.7945 - val_loss: 0.4473 - val_binary_accuracy: 0.7900
Epoch 82/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4109 - binary_accuracy: 0.8100 - val_loss: 0.5535 - val_binary_accuracy: 0.7400
Epoch 83/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4134 - binary_accuracy: 0.8150 - val_loss: 0.5771 - val_binary_accuracy: 0.7240
Epoch 84/100
32/32 [==============================] - 8s 251ms/step - loss: 0.4013 - binary_accuracy: 0.8210 - val_loss: 0.4499 - val_binary_accuracy: 0.7800
Epoch 85/100
32/32 [==============================] - 8s 251ms/step - loss: 0.4045 - binary_accuracy: 0.8205 - val_loss: 0.4520 - val_binary_accuracy: 0.7880
Epoch 86/100
32/32 [==============================] - 8s 253ms/step - loss: 0.4060 - binary_accuracy: 0.8090 - val_loss: 0.4711 - val_binary_accuracy: 0.7760
Epoch 87/100
32/32 [==============================] - 8s 257ms/step - loss: 0.3990 - binary_accuracy: 0.8125 - val_loss: 0.5322 - val_binary_accuracy: 0.7430
Epoch 88/100
32/32 [==============================] - 8s 251ms/step - loss: 0.3723 - binary_accuracy: 0.8315 - val_loss: 0.5687 - val_binary_accuracy: 0.7500
Epoch 89/100
32/32 [==============================] - 8s 251ms/step - loss: 0.3987 - binary_accuracy: 0.8180 - val_loss: 0.6043 - val_binary_accuracy: 0.7290
Epoch 90/100
32/32 [==============================] - 8s 250ms/step - loss: 0.4002 - binary_accuracy: 0.8170 - val_loss: 0.4668 - val_binary_accuracy: 0.7720
Epoch 91/100
32/32 [==============================] - 8s 250ms/step - loss: 0.3821 - binary_accuracy: 0.8275 - val_loss: 0.5863 - val_binary_accuracy: 0.7410
Epoch 92/100
32/32 [==============================] - 8s 251ms/step - loss: 0.4089 - binary_accuracy: 0.8115 - val_loss: 0.4899 - val_binary_accuracy: 0.7590
Epoch 93/100
32/32 [==============================] - 8s 251ms/step - loss: 0.3953 - binary_accuracy: 0.8200 - val_loss: 0.4942 - val_binary_accuracy: 0.7660
Epoch 94/100
32/32 [==============================] - 8s 251ms/step - loss: 0.3827 - binary_accuracy: 0.8275 - val_loss: 0.5453 - val_binary_accuracy: 0.7430
Epoch 95/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3939 - binary_accuracy: 0.8205 - val_loss: 0.4597 - val_binary_accuracy: 0.7770
Epoch 96/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3811 - binary_accuracy: 0.8370 - val_loss: 0.5437 - val_binary_accuracy: 0.7490
Epoch 97/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3731 - binary_accuracy: 0.8370 - val_loss: 0.4411 - val_binary_accuracy: 0.7780
Epoch 98/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3776 - binary_accuracy: 0.8330 - val_loss: 0.4540 - val_binary_accuracy: 0.7820
Epoch 99/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3838 - binary_accuracy: 0.8245 - val_loss: 0.5430 - val_binary_accuracy: 0.7450
Epoch 100/100
32/32 [==============================] - 8s 252ms/step - loss: 0.3801 - binary_accuracy: 0.8245 - val_loss: 0.5083 - val_binary_accuracy: 0.7580</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-13-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> Data augmentation prevents overfitting, as the network never sees twice the same image. Learning is much slower, but it can bring the validation accuracy significantly higher (80% after 100 epochs).</p>
</section>
<section id="transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="transfer-learning">Transfer learning</h2>
<p>Data augmentation helps randomly initialized to learn from small datasets, but the best solution is to start training with already good weights.</p>
<p><strong>Transfer learning</strong> allows to reuse the weights of a CNN trained on a bigger dataset (e.g.&nbsp;ImageNet) to either extract features for a shallow classifier or to allow fine-tuning of all weights.</p>
<p>Keras provides a considerable number of pre-trained CNNs:</p>
<p><a href="https://keras.io/api/applications/" class="uri">https://keras.io/api/applications/</a></p>
<p>In this exercise, we will use the Xception network for feature extraction, but feel free to experiment with other architectures. To download the weights and create the keras model, simply call:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>xception <span class="op">=</span> tf.keras.applications.Xception(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span><span class="st">"imagenet"</span>,  <span class="co"># Load weights pre-trained on ImageNet.</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>), <span class="co"># Input shape</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>        include_top<span class="op">=</span><span class="va">False</span>, <span class="co"># Only the convolutional layers, not the last fully-connected ones</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>include_top=False</code> removes the last fully-connected layers used to predict the ImageNet classes, as we only care about the binary cat/dog classification.</p>
<p><strong>Q:</strong> Download Xception and print its summary. Make sense of the various layers (the paper might help: <a href="http://arxiv.org/abs/1610.02357" class="uri">http://arxiv.org/abs/1610.02357</a>). What is the size of the final tensor?</p>
<div class="cell" data-outputid="e88da09d-92b5-4c44-8d2c-3679628cec78" data-execution_count="13">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>xception <span class="op">=</span> tf.keras.applications.Xception(</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span><span class="st">"imagenet"</span>,  <span class="co"># Load weights pre-trained on ImageNet.</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>), <span class="co"># Input shape</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        include_top<span class="op">=</span><span class="va">False</span>, <span class="co"># Only the convolutional layers, not the last fully-connected ones</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(xception.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5
83689472/83683744 [==============================] - 11s 0us/step
83697664/83683744 [==============================] - 11s 0us/step
Model: "xception"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               
                                )]                                                                
                                                                                                  
 block1_conv1 (Conv2D)          (None, 74, 74, 32)   864         ['input_1[0][0]']                
                                                                                                  
 block1_conv1_bn (BatchNormaliz  (None, 74, 74, 32)  128         ['block1_conv1[0][0]']           
 ation)                                                                                           
                                                                                                  
 block1_conv1_act (Activation)  (None, 74, 74, 32)   0           ['block1_conv1_bn[0][0]']        
                                                                                                  
 block1_conv2 (Conv2D)          (None, 72, 72, 64)   18432       ['block1_conv1_act[0][0]']       
                                                                                                  
 block1_conv2_bn (BatchNormaliz  (None, 72, 72, 64)  256         ['block1_conv2[0][0]']           
 ation)                                                                                           
                                                                                                  
 block1_conv2_act (Activation)  (None, 72, 72, 64)   0           ['block1_conv2_bn[0][0]']        
                                                                                                  
 block2_sepconv1 (SeparableConv  (None, 72, 72, 128)  8768       ['block1_conv2_act[0][0]']       
 2D)                                                                                              
                                                                                                  
 block2_sepconv1_bn (BatchNorma  (None, 72, 72, 128)  512        ['block2_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block2_sepconv2_act (Activatio  (None, 72, 72, 128)  0          ['block2_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block2_sepconv2 (SeparableConv  (None, 72, 72, 128)  17536      ['block2_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block2_sepconv2_bn (BatchNorma  (None, 72, 72, 128)  512        ['block2_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 conv2d (Conv2D)                (None, 36, 36, 128)  8192        ['block1_conv2_act[0][0]']       
                                                                                                  
 block2_pool (MaxPooling2D)     (None, 36, 36, 128)  0           ['block2_sepconv2_bn[0][0]']     
                                                                                                  
 batch_normalization (BatchNorm  (None, 36, 36, 128)  512        ['conv2d[0][0]']                 
 alization)                                                                                       
                                                                                                  
 add (Add)                      (None, 36, 36, 128)  0           ['block2_pool[0][0]',            
                                                                  'batch_normalization[0][0]']    
                                                                                                  
 block3_sepconv1_act (Activatio  (None, 36, 36, 128)  0          ['add[0][0]']                    
 n)                                                                                               
                                                                                                  
 block3_sepconv1 (SeparableConv  (None, 36, 36, 256)  33920      ['block3_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block3_sepconv1_bn (BatchNorma  (None, 36, 36, 256)  1024       ['block3_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block3_sepconv2_act (Activatio  (None, 36, 36, 256)  0          ['block3_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block3_sepconv2 (SeparableConv  (None, 36, 36, 256)  67840      ['block3_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block3_sepconv2_bn (BatchNorma  (None, 36, 36, 256)  1024       ['block3_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 conv2d_1 (Conv2D)              (None, 18, 18, 256)  32768       ['add[0][0]']                    
                                                                                                  
 block3_pool (MaxPooling2D)     (None, 18, 18, 256)  0           ['block3_sepconv2_bn[0][0]']     
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 18, 18, 256)  1024       ['conv2d_1[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 add_1 (Add)                    (None, 18, 18, 256)  0           ['block3_pool[0][0]',            
                                                                  'batch_normalization_1[0][0]']  
                                                                                                  
 block4_sepconv1_act (Activatio  (None, 18, 18, 256)  0          ['add_1[0][0]']                  
 n)                                                                                               
                                                                                                  
 block4_sepconv1 (SeparableConv  (None, 18, 18, 728)  188672     ['block4_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block4_sepconv1_bn (BatchNorma  (None, 18, 18, 728)  2912       ['block4_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block4_sepconv2_act (Activatio  (None, 18, 18, 728)  0          ['block4_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block4_sepconv2 (SeparableConv  (None, 18, 18, 728)  536536     ['block4_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block4_sepconv2_bn (BatchNorma  (None, 18, 18, 728)  2912       ['block4_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 conv2d_2 (Conv2D)              (None, 9, 9, 728)    186368      ['add_1[0][0]']                  
                                                                                                  
 block4_pool (MaxPooling2D)     (None, 9, 9, 728)    0           ['block4_sepconv2_bn[0][0]']     
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 9, 9, 728)   2912        ['conv2d_2[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 add_2 (Add)                    (None, 9, 9, 728)    0           ['block4_pool[0][0]',            
                                                                  'batch_normalization_2[0][0]']  
                                                                                                  
 block5_sepconv1_act (Activatio  (None, 9, 9, 728)   0           ['add_2[0][0]']                  
 n)                                                                                               
                                                                                                  
 block5_sepconv1 (SeparableConv  (None, 9, 9, 728)   536536      ['block5_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block5_sepconv1_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block5_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block5_sepconv2_act (Activatio  (None, 9, 9, 728)   0           ['block5_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block5_sepconv2 (SeparableConv  (None, 9, 9, 728)   536536      ['block5_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block5_sepconv2_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block5_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 block5_sepconv3_act (Activatio  (None, 9, 9, 728)   0           ['block5_sepconv2_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block5_sepconv3 (SeparableConv  (None, 9, 9, 728)   536536      ['block5_sepconv3_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block5_sepconv3_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block5_sepconv3[0][0]']        
 lization)                                                                                        
                                                                                                  
 add_3 (Add)                    (None, 9, 9, 728)    0           ['block5_sepconv3_bn[0][0]',     
                                                                  'add_2[0][0]']                  
                                                                                                  
 block6_sepconv1_act (Activatio  (None, 9, 9, 728)   0           ['add_3[0][0]']                  
 n)                                                                                               
                                                                                                  
 block6_sepconv1 (SeparableConv  (None, 9, 9, 728)   536536      ['block6_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block6_sepconv1_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block6_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block6_sepconv2_act (Activatio  (None, 9, 9, 728)   0           ['block6_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block6_sepconv2 (SeparableConv  (None, 9, 9, 728)   536536      ['block6_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block6_sepconv2_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block6_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 block6_sepconv3_act (Activatio  (None, 9, 9, 728)   0           ['block6_sepconv2_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block6_sepconv3 (SeparableConv  (None, 9, 9, 728)   536536      ['block6_sepconv3_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block6_sepconv3_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block6_sepconv3[0][0]']        
 lization)                                                                                        
                                                                                                  
 add_4 (Add)                    (None, 9, 9, 728)    0           ['block6_sepconv3_bn[0][0]',     
                                                                  'add_3[0][0]']                  
                                                                                                  
 block7_sepconv1_act (Activatio  (None, 9, 9, 728)   0           ['add_4[0][0]']                  
 n)                                                                                               
                                                                                                  
 block7_sepconv1 (SeparableConv  (None, 9, 9, 728)   536536      ['block7_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block7_sepconv1_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block7_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block7_sepconv2_act (Activatio  (None, 9, 9, 728)   0           ['block7_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block7_sepconv2 (SeparableConv  (None, 9, 9, 728)   536536      ['block7_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block7_sepconv2_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block7_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 block7_sepconv3_act (Activatio  (None, 9, 9, 728)   0           ['block7_sepconv2_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block7_sepconv3 (SeparableConv  (None, 9, 9, 728)   536536      ['block7_sepconv3_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block7_sepconv3_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block7_sepconv3[0][0]']        
 lization)                                                                                        
                                                                                                  
 add_5 (Add)                    (None, 9, 9, 728)    0           ['block7_sepconv3_bn[0][0]',     
                                                                  'add_4[0][0]']                  
                                                                                                  
 block8_sepconv1_act (Activatio  (None, 9, 9, 728)   0           ['add_5[0][0]']                  
 n)                                                                                               
                                                                                                  
 block8_sepconv1 (SeparableConv  (None, 9, 9, 728)   536536      ['block8_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block8_sepconv1_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block8_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block8_sepconv2_act (Activatio  (None, 9, 9, 728)   0           ['block8_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block8_sepconv2 (SeparableConv  (None, 9, 9, 728)   536536      ['block8_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block8_sepconv2_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block8_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 block8_sepconv3_act (Activatio  (None, 9, 9, 728)   0           ['block8_sepconv2_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block8_sepconv3 (SeparableConv  (None, 9, 9, 728)   536536      ['block8_sepconv3_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block8_sepconv3_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block8_sepconv3[0][0]']        
 lization)                                                                                        
                                                                                                  
 add_6 (Add)                    (None, 9, 9, 728)    0           ['block8_sepconv3_bn[0][0]',     
                                                                  'add_5[0][0]']                  
                                                                                                  
 block9_sepconv1_act (Activatio  (None, 9, 9, 728)   0           ['add_6[0][0]']                  
 n)                                                                                               
                                                                                                  
 block9_sepconv1 (SeparableConv  (None, 9, 9, 728)   536536      ['block9_sepconv1_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block9_sepconv1_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block9_sepconv1[0][0]']        
 lization)                                                                                        
                                                                                                  
 block9_sepconv2_act (Activatio  (None, 9, 9, 728)   0           ['block9_sepconv1_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block9_sepconv2 (SeparableConv  (None, 9, 9, 728)   536536      ['block9_sepconv2_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block9_sepconv2_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block9_sepconv2[0][0]']        
 lization)                                                                                        
                                                                                                  
 block9_sepconv3_act (Activatio  (None, 9, 9, 728)   0           ['block9_sepconv2_bn[0][0]']     
 n)                                                                                               
                                                                                                  
 block9_sepconv3 (SeparableConv  (None, 9, 9, 728)   536536      ['block9_sepconv3_act[0][0]']    
 2D)                                                                                              
                                                                                                  
 block9_sepconv3_bn (BatchNorma  (None, 9, 9, 728)   2912        ['block9_sepconv3[0][0]']        
 lization)                                                                                        
                                                                                                  
 add_7 (Add)                    (None, 9, 9, 728)    0           ['block9_sepconv3_bn[0][0]',     
                                                                  'add_6[0][0]']                  
                                                                                                  
 block10_sepconv1_act (Activati  (None, 9, 9, 728)   0           ['add_7[0][0]']                  
 on)                                                                                              
                                                                                                  
 block10_sepconv1 (SeparableCon  (None, 9, 9, 728)   536536      ['block10_sepconv1_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block10_sepconv1_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block10_sepconv1[0][0]']       
 alization)                                                                                       
                                                                                                  
 block10_sepconv2_act (Activati  (None, 9, 9, 728)   0           ['block10_sepconv1_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block10_sepconv2 (SeparableCon  (None, 9, 9, 728)   536536      ['block10_sepconv2_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block10_sepconv2_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block10_sepconv2[0][0]']       
 alization)                                                                                       
                                                                                                  
 block10_sepconv3_act (Activati  (None, 9, 9, 728)   0           ['block10_sepconv2_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block10_sepconv3 (SeparableCon  (None, 9, 9, 728)   536536      ['block10_sepconv3_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block10_sepconv3_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block10_sepconv3[0][0]']       
 alization)                                                                                       
                                                                                                  
 add_8 (Add)                    (None, 9, 9, 728)    0           ['block10_sepconv3_bn[0][0]',    
                                                                  'add_7[0][0]']                  
                                                                                                  
 block11_sepconv1_act (Activati  (None, 9, 9, 728)   0           ['add_8[0][0]']                  
 on)                                                                                              
                                                                                                  
 block11_sepconv1 (SeparableCon  (None, 9, 9, 728)   536536      ['block11_sepconv1_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block11_sepconv1_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block11_sepconv1[0][0]']       
 alization)                                                                                       
                                                                                                  
 block11_sepconv2_act (Activati  (None, 9, 9, 728)   0           ['block11_sepconv1_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block11_sepconv2 (SeparableCon  (None, 9, 9, 728)   536536      ['block11_sepconv2_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block11_sepconv2_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block11_sepconv2[0][0]']       
 alization)                                                                                       
                                                                                                  
 block11_sepconv3_act (Activati  (None, 9, 9, 728)   0           ['block11_sepconv2_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block11_sepconv3 (SeparableCon  (None, 9, 9, 728)   536536      ['block11_sepconv3_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block11_sepconv3_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block11_sepconv3[0][0]']       
 alization)                                                                                       
                                                                                                  
 add_9 (Add)                    (None, 9, 9, 728)    0           ['block11_sepconv3_bn[0][0]',    
                                                                  'add_8[0][0]']                  
                                                                                                  
 block12_sepconv1_act (Activati  (None, 9, 9, 728)   0           ['add_9[0][0]']                  
 on)                                                                                              
                                                                                                  
 block12_sepconv1 (SeparableCon  (None, 9, 9, 728)   536536      ['block12_sepconv1_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block12_sepconv1_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block12_sepconv1[0][0]']       
 alization)                                                                                       
                                                                                                  
 block12_sepconv2_act (Activati  (None, 9, 9, 728)   0           ['block12_sepconv1_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block12_sepconv2 (SeparableCon  (None, 9, 9, 728)   536536      ['block12_sepconv2_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block12_sepconv2_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block12_sepconv2[0][0]']       
 alization)                                                                                       
                                                                                                  
 block12_sepconv3_act (Activati  (None, 9, 9, 728)   0           ['block12_sepconv2_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block12_sepconv3 (SeparableCon  (None, 9, 9, 728)   536536      ['block12_sepconv3_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block12_sepconv3_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block12_sepconv3[0][0]']       
 alization)                                                                                       
                                                                                                  
 add_10 (Add)                   (None, 9, 9, 728)    0           ['block12_sepconv3_bn[0][0]',    
                                                                  'add_9[0][0]']                  
                                                                                                  
 block13_sepconv1_act (Activati  (None, 9, 9, 728)   0           ['add_10[0][0]']                 
 on)                                                                                              
                                                                                                  
 block13_sepconv1 (SeparableCon  (None, 9, 9, 728)   536536      ['block13_sepconv1_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block13_sepconv1_bn (BatchNorm  (None, 9, 9, 728)   2912        ['block13_sepconv1[0][0]']       
 alization)                                                                                       
                                                                                                  
 block13_sepconv2_act (Activati  (None, 9, 9, 728)   0           ['block13_sepconv1_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block13_sepconv2 (SeparableCon  (None, 9, 9, 1024)  752024      ['block13_sepconv2_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block13_sepconv2_bn (BatchNorm  (None, 9, 9, 1024)  4096        ['block13_sepconv2[0][0]']       
 alization)                                                                                       
                                                                                                  
 conv2d_3 (Conv2D)              (None, 5, 5, 1024)   745472      ['add_10[0][0]']                 
                                                                                                  
 block13_pool (MaxPooling2D)    (None, 5, 5, 1024)   0           ['block13_sepconv2_bn[0][0]']    
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 5, 5, 1024)  4096        ['conv2d_3[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 add_11 (Add)                   (None, 5, 5, 1024)   0           ['block13_pool[0][0]',           
                                                                  'batch_normalization_3[0][0]']  
                                                                                                  
 block14_sepconv1 (SeparableCon  (None, 5, 5, 1536)  1582080     ['add_11[0][0]']                 
 v2D)                                                                                             
                                                                                                  
 block14_sepconv1_bn (BatchNorm  (None, 5, 5, 1536)  6144        ['block14_sepconv1[0][0]']       
 alization)                                                                                       
                                                                                                  
 block14_sepconv1_act (Activati  (None, 5, 5, 1536)  0           ['block14_sepconv1_bn[0][0]']    
 on)                                                                                              
                                                                                                  
 block14_sepconv2 (SeparableCon  (None, 5, 5, 2048)  3159552     ['block14_sepconv1_act[0][0]']   
 v2D)                                                                                             
                                                                                                  
 block14_sepconv2_bn (BatchNorm  (None, 5, 5, 2048)  8192        ['block14_sepconv2[0][0]']       
 alization)                                                                                       
                                                                                                  
 block14_sepconv2_act (Activati  (None, 5, 5, 2048)  0           ['block14_sepconv2_bn[0][0]']    
 on)                                                                                              
                                                                                                  
==================================================================================================
Total params: 20,861,480
Trainable params: 20,806,952
Non-trainable params: 54,528
__________________________________________________________________________________________________
None</code></pre>
</div>
</div>
<p>Let’s now use transfer learning using this network. The first thing to do is to freeze Xception to make sure that it does learn from the cats and dogs data:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>xception.trainable <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then connect Xception to the inputs, making sure again that the network won’t learn (in particular, the parameters of batch normalization are kept):</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> xception(inputs, training<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can now use the layer <code>x</code> and stack what we want on top of it. Instead of flattening the 5x5x2048 tensor, it is usually better to apply <strong>average-pooling</strong> (or mean-pooling) on each 5x5 feature map to obtain a vector with 2048 elements:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.layers.GlobalAveragePooling2D()(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Q:</strong> Perform a soft linear classification on this vector with 2048 elements to recognize cats from dogs (using non-augmented data). Do not hesitate to use some dropout and to boost your learning rate, there are only 2049 trainable parameters. Conclude.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transfer_model():</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Delete all previous models to free memory</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    tf.keras.backend.clear_session()</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use Xception as a feature extractor</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    xception <span class="op">=</span> tf.keras.applications.Xception(</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span><span class="st">"imagenet"</span>,  <span class="co"># Load weights pre-trained on ImageNet.</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>        input_shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>), <span class="co"># Input shape</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>        include_top<span class="op">=</span><span class="va">False</span>, <span class="co"># Only the convolutional layers, not the last fully-connected ones</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>    )  <span class="co"># Do not include the ImageNet classifier at the top.</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Freeze the base model</span></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>    xception.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create new model on top</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The base model contains batchnorm layers. We want to keep them in inference mode</span></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># when we unfreeze the base model for fine-tuning, so we make sure that the</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># base_model is running in inference mode here.</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> xception(inputs, training<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># GlobalAveragePooling2D applies average-pooling on each 5x5 feature map</span></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.GlobalAveragePooling2D()(x)</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Regularize with dropout</span></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dropout(<span class="fl">0.5</span>)(x)  </span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Output layer for binary classification</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(x)</span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model</span></span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.Model(inputs, outputs)</span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>),</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>[<span class="st">'binary_accuracy'</span>],</span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(model.summary())</span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="22014124-3b90-4093-8c5c-6bcb750e1424" data-execution_count="15">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> transfer_model()</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> tf.keras.callbacks.History()</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>      train_generator,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>      epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>      validation_data<span class="op">=</span>validation_generator,</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>      callbacks<span class="op">=</span>[history])</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">121</span>)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">122</span>)</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'binary_accuracy'</span>], <span class="st">'-r'</span>, label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_binary_accuracy'</span>], <span class="st">'-b'</span>, label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch #'</span>)</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 150, 3)]     0         
                                                                 
 xception (Functional)       (None, 5, 5, 2048)        20861480  
                                                                 
 global_average_pooling2d (G  (None, 2048)             0         
 lobalAveragePooling2D)                                          
                                                                 
 dropout (Dropout)           (None, 2048)              0         
                                                                 
 dense (Dense)               (None, 1)                 2049      
                                                                 
=================================================================
Total params: 20,863,529
Trainable params: 2,049
Non-trainable params: 20,861,480
_________________________________________________________________
None
Epoch 1/10</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 11:09:19.851972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - ETA: 0s - loss: 0.3178 - binary_accuracy: 0.8790</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-15 11:09:28.778983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>32/32 [==============================] - 13s 343ms/step - loss: 0.3178 - binary_accuracy: 0.8790 - val_loss: 0.1438 - val_binary_accuracy: 0.9470
Epoch 2/10
32/32 [==============================] - 10s 317ms/step - loss: 0.1343 - binary_accuracy: 0.9530 - val_loss: 0.1119 - val_binary_accuracy: 0.9550
Epoch 3/10
32/32 [==============================] - 10s 317ms/step - loss: 0.1121 - binary_accuracy: 0.9620 - val_loss: 0.0979 - val_binary_accuracy: 0.9620
Epoch 4/10
32/32 [==============================] - 10s 317ms/step - loss: 0.0916 - binary_accuracy: 0.9660 - val_loss: 0.0965 - val_binary_accuracy: 0.9590
Epoch 5/10
32/32 [==============================] - 10s 323ms/step - loss: 0.0858 - binary_accuracy: 0.9675 - val_loss: 0.0919 - val_binary_accuracy: 0.9620
Epoch 6/10
32/32 [==============================] - 10s 318ms/step - loss: 0.0798 - binary_accuracy: 0.9730 - val_loss: 0.0917 - val_binary_accuracy: 0.9630
Epoch 7/10
32/32 [==============================] - 10s 317ms/step - loss: 0.0727 - binary_accuracy: 0.9750 - val_loss: 0.0879 - val_binary_accuracy: 0.9640
Epoch 8/10
32/32 [==============================] - 10s 319ms/step - loss: 0.0672 - binary_accuracy: 0.9795 - val_loss: 0.0846 - val_binary_accuracy: 0.9600
Epoch 9/10
32/32 [==============================] - 10s 318ms/step - loss: 0.0689 - binary_accuracy: 0.9705 - val_loss: 0.0839 - val_binary_accuracy: 0.9590
Epoch 10/10
32/32 [==============================] - 10s 320ms/step - loss: 0.0634 - binary_accuracy: 0.9785 - val_loss: 0.0854 - val_binary_accuracy: 0.9630</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11-TransferLearning-solution_files/figure-html/cell-16-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>A:</strong> Using feature extraction, we obtain very quickly a validation accuracy around 95% on the small unaugmented dataset, a performance out of reach of randomly initialized networks even with data augmentation. Conclusion: if you can use transfer learning, use it.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../exercises/10-CNN-solution.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Convolutional neural networks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../exercises/12-VAE-solution.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-title">Variational autoencoder</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">Copyright 2022, Julien Vitay - <a href="mailto:julien.vitay@informatik.tu-chemnitz.de" class="email">julien.vitay@informatik.tu-chemnitz.de</a></div>
  </div>
</footer>



<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>