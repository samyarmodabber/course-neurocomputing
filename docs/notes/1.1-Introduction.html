<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.175">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Neurocomputing - 1&nbsp; Introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notes/1.2-Math.html" rel="next">
<link href="../index.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Neurocomputing</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Course description</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Introduction</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.1-Introduction.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/1.2-Math.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Math basics (optional)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Linear algorithms</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Neural networks</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Convolutional neural networks</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Unsupervised learning and generative modeling</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Recurrent neural networks</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Self-supervised learning</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Outlook</span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">Exercises</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/1-Python-solution.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction To Python</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-neurocomputing" id="toc-what-is-neurocomputing" class="nav-link active" data-scroll-target="#what-is-neurocomputing"><span class="toc-section-number">1.1</span>  What is neurocomputing?</a></li>
  <li><a href="#applications-of-deep-learning" id="toc-applications-of-deep-learning" class="nav-link" data-scroll-target="#applications-of-deep-learning"><span class="toc-section-number">1.2</span>  Applications of deep learning</a>
  <ul class="collapse">
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning"><span class="toc-section-number">1.2.1</span>  Supervised learning</a></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning"><span class="toc-section-number">1.2.2</span>  Unsupervised learning</a></li>
  </ul></li>
  <li><a href="#outlook" id="toc-outlook" class="nav-link" data-scroll-target="#outlook"><span class="toc-section-number">1.3</span>  Outlook</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>Slides: <a href="../slides/1.1-Introduction.html" target="_blank">html</a> <a href="../slides/pdf/1.1-Introduction.pdf" target="_blank">pdf</a></p>
<section id="what-is-neurocomputing" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="what-is-neurocomputing"><span class="header-section-number">1.1</span> What is neurocomputing?</h2>
<p></p><div id="youtube-frame" style="position: relative; padding-bottom: 56.25%; /* 16:9 */ height: 0;"><iframe width="100%" height="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/Hy0FpFjdJGI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p>Let’s first discuss the difference between Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) and Neurocomputing. Nowadays, these terms are used almost interchangeably, but there are historical and methodological differences.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../slides/img/aimldl.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">Source: <a href="https://data-science-blog.com/blog/2018/05/14/machine-learning-vs-deep-learning-wo-liegt-der-unterschied" class="uri">https://data-science-blog.com/blog/2018/05/14/machine-learning-vs-deep-learning-wo-liegt-der-unterschied</a></figcaption><p></p>
</figure>
</div>
<p>The term <strong>Artificial Intelligence</strong> was coined by John McCarthy at the Dartmouth Summer Research Project on Artificial Intelligence in <strong>1956</strong>:</p>
<blockquote class="blockquote">
<p>The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.</p>
</blockquote>
<p>Good old-fashion AI (GOFAI) approaches were purely symbolic (logical systems, knowledge-based systems) or using linear neural networks. They were able to play checkers, prove mathematical theorems, make simple conversations (ELIZA), translate languages…</p>
<p><strong>Machine learning</strong> (ML) is a branch of AI that focuses on <strong>learning from examples</strong> (data-driven AI). It is sometimes also referred to as big data, data science, operational research, pattern recognition… ML algorithms include:</p>
<ul>
<li>Artificial Neural Networks (multi-layer perceptrons)</li>
<li>Statistical analysis (Bayesian modeling, PCA)</li>
<li>Clustering algorithms (k-means, GMM, spectral clustering)</li>
<li>Support vector machines</li>
<li>Decision trees, random forests</li>
</ul>
<p><strong>Deep Learning</strong> is a recent re-branding of artificial neural networks. It focuses on learning high-level representations of the data, using highly non-linear neural networks. Many architectures have been developped, including:</p>
<ul>
<li>Deep neural networks (DNN)</li>
<li>Convolutional neural networks (CNN)</li>
<li>Recurrent neural networks (RNN)</li>
<li>Generative models (GAN, VAE)</li>
<li>Deep reinforcement learning (DQN, PPO, AlphaGo)</li>
<li>Transformers</li>
<li>Graph neural networks</li>
</ul>
<p><img src="img/neurocomputing.svg" class="img-fluid" style="width:60.0%"></p>
<p><strong>Neurocomputing</strong> is at the intersection between computational neuroscience and artificial neural networks (deep learning). <strong>Computational neuroscience</strong> studies the functioning of the brain (human or animal) through biologically detailed models, either at the functional level (e.g.&nbsp;visual attention, decision-making) or cellular level (individual neurons, synapses, neurotransmitters, etc). The goal of computational neuroscience is 1) to provide theoretical explanations to the experimental observations made by neuroscientists and 2) make predictions that can be verified experimentally. Moreover, understanding how the brain solves real-life problems might allow to design better AI algorithms. If you are interested in computational neuroscience, make sure to visit the courses <strong>Neurokognition</strong> I and II taught by Prof.&nbsp;Dr.&nbsp;Hamker:</p>
<p><a href="https://www.tu-chemnitz.de/informatik/KI/edu/neurokognition/" class="uri">https://www.tu-chemnitz.de/informatik/KI/edu/neurokognition/</a></p>
<p>Neurocomputing aims at bringing the mechanisms underlying human cognition into artificial intelligence. The first part of this course focuses on deep learning, while the second will discuss how more biologically realistic neural networks could help designing better AI systems.</p>
</section>
<section id="applications-of-deep-learning" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="applications-of-deep-learning"><span class="header-section-number">1.2</span> Applications of deep learning</h2>
<p>Machine Learning applications are generally divided into three main branches:</p>
<ul>
<li><p><strong>Supervised learning</strong>: The program is trained on a pre-defined set of training examples and used to make correct predictions when given new data.</p></li>
<li><p><strong>Unsupervised learning</strong>: The program is given a bunch of data and must find patterns and relationships therein.</p></li>
<li><p><strong>Reinforcement learning</strong>: The program explores its environment by producing actions and receiving rewards.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ml-areas.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Source: <a href="http://www.isaziconsulting.co.za/machinelearning.html" class="uri">http://www.isaziconsulting.co.za/machinelearning.html</a></figcaption><p></p>
</figure>
</div>
<p>Deep learning has recently revolutionized these types of machine learning, so let’s have a look at some concrete examples for motivation. At the end of the course, if you also perform all exercises, you should be able to reproduce these applications.</p>
<section id="supervised-learning" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="supervised-learning"><span class="header-section-number">1.2.1</span> Supervised learning</h3>
<p></p><div id="youtube-frame" style="position: relative; padding-bottom: 56.25%; /* 16:9 */ height: 0;"><iframe width="100%" height="" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/pbbzwFohH3I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/supervisedlearning.png" class="img-fluid figure-img" style="width:50.0%"></p>
<p></p><figcaption class="figure-caption">Principle of supervised learning. Source: Andrew Ng, Stanford CS229, <a href="https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf" class="uri">https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf</a></figcaption><p></p>
</figure>
</div>
<p>In a supervised learning, we have a <strong>training set</strong> (or training data) consisting of <span class="math inline">\(N\)</span> samples (or examples) from which we want to learn the underlying function or distribution. Each sample consists of an <strong>input</strong> <span class="math inline">\(\mathbf{x}_i\)</span> and an <strong>output</strong> (also called ground truth, desired output or target) <span class="math inline">\(t_i\)</span>.</p>
<p>What we want to learn is <strong>parameterized model</strong> <span class="math inline">\(y_i = f_\theta (\mathbf{x}_i)\)</span> which can predict the correct output for the inputs of the training set. The goal of <strong>learning</strong> (or training) is to find which value of the parameters <span class="math inline">\(\theta\)</span> allows to reduce (<em>minimize</em>) the <strong>prediction error</strong>. i.e.&nbsp;the discrepancy between the prediction <span class="math inline">\(y_i = f_\theta (\mathbf{x}_i)\)</span> and the desired output <span class="math inline">\(t_i\)</span>.</p>
<p>Depending on the nature of the outputs <span class="math inline">\(t\)</span>, we have two different supervised problems:</p>
<ul>
<li>In <strong>regression</strong> tasks, the outputs can take an infinity of values (e.g.&nbsp;real numbers). The following figure shows how examples of flat surfaces (input <span class="math inline">\(x_i\)</span>) and prices (output <span class="math inline">\(t_i\)</span>) collected in the neighborhood can be used to predict the price of a new flat. After collecting enough samples, a model is trained to minimize its prediction error. Here, a linear model is used (black line) as we perform <strong>linear regression</strong>, but any other type of function could be used. The parameters of the line (slope and intercept) are adapted so that the line lies close to the data: the predicted price <span class="math inline">\(y_i\)</span> is never far from the ground truth <span class="math inline">\(t_i\)</span>. Using that line after learning, we can predict that a 60 square meters flat should be rented around 550 euros/month.</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>````{figure} ../img/regression-animation3.png</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 80%</td>
</tr>
</tbody>
</table>
<pre><code>
* In **classification** tasks, the outputs are discrete, i.e. take only a finite number of different values (called classes or labels). When there are only two classes, they are called the positive and negative classes and the problem is a **binary classification**. The two classes can represent yes/no binary values, such as when when a test is positive or negative. When there are more than two classes, they can for example represent different objects (car / bike / dog / cat...) that can be recognized on an image. The following figure depicts a binary classifiation problem, where two input features $x_1$ and $x_2$ (temperature and blood pressure) are used to predict the occurence of an illness (yes = ill, no = sane). The linear model is a line that separates the input space into two separate regions: all points above the line are categorized (classified) as ill, all points below as sane, even if they were not in the training data.

````{figure} ../img/classification-animation3.png
---
width: 80%
---</code></pre>
<p>In practice, when using neural networks, the distinction between classification and regression is not very important, but it can be relevant for other ML techniques (decision trees only work for classification problems, for example).</p>
<section id="feedforward-neural-networks" class="level4" data-number="1.2.1.1">
<h4 data-number="1.2.1.1" class="anchored" data-anchor-id="feedforward-neural-networks"><span class="header-section-number">1.2.1.1</span> Feedforward neural networks</h4>
<p>As we will see later, an <strong>artificial neuron</strong> is a mathematical model able to perform <strong>linear</strong> classification or regression using weighted sums of inputs:</p>
<p><span class="math display">\[y = f(\sum_{i=1}^d w_i \, x_i + b)\]</span></p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/artificialneuron.svg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 60%</td>
</tr>
</tbody>
</table>
<p>Artificial neuron.</p>
<pre><code>
By stacking layers of artificial neurons, we obtain a **feedforward neural network** able to solve non-linear classification and regression problems.

```{figure} ../img/deep.svg
---
width: 60%
---
Feedforward neural network.</code></pre>
<p><em>Fully-connected layers</em> of neurons can be replaced by <em>convolutional layers</em> when dealing with images as inputs, leading to the very successful <strong>convolutional neural networks</strong> (CNN).</p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/dcn.png</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 90%</td>
</tr>
</tbody>
</table>
<p>Typical CNN architecture. Source: Albelwi S, Mahmood A. 2017. A Framework for Designing the Architectures of Deep Convolutional Neural Networks. Entropy 19:242. doi:10.3390/e19060242</p>
<pre><code>
The "only" thing to do is to feed these networks with a lot of training data (inputs and desired outputs) and let them adjust their weights to minimize their prediction error using the backpropagation algorithm {cite}`Rumelhart1986a` (more on that later). Neural networks (including CNNs) are a very old technology, dating back from the 60's, with a resurgence in the 80's thanks to the backpropation algorithm. They had been able to learn small datasets, but their performance was limited by the availability of data and the computing power available at the time. One classical example is the use of a CNN {cite}`LeCun1998` by Yann LeCun in 1998 to automatically classify single digits on ZIP postal codes (what led to the development of the MNIST dataset, the "Hello World!" of machine learning which we will use in the exercises). 

```{figure} ../img/lenet5.gif
---
width: 50%
---
LeNet5 CNN trained on MNIST. Source: &lt;http://yann.lecun.com/exdb/lenet/&gt;</code></pre>
<p>The revival of artificial neural networks marketed as <strong>deep learning</strong> at the end of the 2000’s was principally due the availability of massive amounts of training data (thanks to search engines and social networks) and the availability of consumer graphics GPUs able to perform scientific computations, especially using Nvidia’s CUDA programming framework.</p>
<p>The first badge of honour obtained by deep learning methods happened during the <a href="https://image-net.org">ImageNet</a> challenge in 2012. The challenge was made for computer vision (CV) scientists to compare their algorithms on a huge dataset of 14 billion annotated images for object recognition (what is on the image?), object detection (which objects are in the image and where?) and object segmentation (which pixels belong to which object?). The object recognition challenge was indeed quite hard, with 1000 different classes (sometimes exotic, such as “ladle” or “porcupine”) with a great variety of backgrounds or lightning conditions. Classical CV methods based on feature extraction and simple classifiers performed reasonably well, with an error rate around 30%.</p>
<p>However, Krizhevsky, Sutskever and Hinton {cite}<code>Krizhevsky2012</code> trained a CNN entirely on the images, without any form of preprocessing, and obtained an error rate of 15%, half of the other methods. This achievement marked the beginning of the deep learning era, attracted the attention of the major industrial players (Google, Facebook and soon the rest of the world) who have already invested hundreds of billions on AI research.</p>
<p>The whole field of computer vision was taken by storm, and CNNs were able to outperform the state-of-the-art of many vision-related tasks, such as object detection with the YOLO (You Only Look Once) network {cite}<code>Redmon2016</code>:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/MPU2HistivI" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>or semantic segmention with SegNet {cite}<code>Badrinarayanan2016</code> or its variants such as Mask RCNN {cite}<code>He2018</code>:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/OOT3UIXZztE" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>CNNs can even be used to control autonomous cars, by learning to reproduce human commands for a given input image {cite}<code>Bojarski2016</code>:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/qhUvQiKec2U" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>CNNs are also gaining an increasing importance in medical applications, for example to help histologists detect cancerous cells:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/9Mz84cwVmS0" frameborder="0" allowfullscreen="">
</iframe>
</div>
</section>
<section id="recurrent-neural-networks" class="level4" data-number="1.2.1.2">
<h4 data-number="1.2.1.2" class="anchored" data-anchor-id="recurrent-neural-networks"><span class="header-section-number">1.2.1.2</span> Recurrent neural networks</h4>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/_809brCJaTM" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>Another field that was heavily transformed by deep learning is <strong>natural language processing</strong> (NLP), i.e.&nbsp;the automatic processing of language, be it text understanding, translation, summarization, question answering or even speech recognition and synthesis. In short, everything needed under the hood when you talk to Siri or Alexa.</p>
<p>The key neural network involved in this paradigmatic change is the <strong>recurrent neural network</strong> (RNN), with the most prominent model being the <strong>long short-term memory</strong> (LSTM) network {cite}<code>Hochreiter1997</code>.</p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/LSTM3-chain.png</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 90%</td>
</tr>
</tbody>
</table>
<p>LSTM cell. Source: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="uri">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
<pre><code>
The main difference with feedforward neural networks is that RNNs can be applied on sequences (of words, but it could also be video frames or any time-dependent signal). At each step, a RNN produces an output not only depending on its current input, but also on its previous output, implementing a form of memory of past events. 

More recent advances furthermore introduce the concept of **attention** for processing sequences. This is now at the heart of all translation systems or in BERT, the language understanding module behind Google search. The neural architectures may seem complex, but we will break them down in this course.

```{figure} ../img/google-nmt-lstm.png
---
width: 100%
---
Google Neural Machine Translation. Source: &lt;https://ai.google/research/pubs/pub45610&gt;</code></pre>
</section>
</section>
<section id="unsupervised-learning" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="unsupervised-learning"><span class="header-section-number">1.2.2</span> Unsupervised learning</h3>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/uIrBgz4OPlM" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>In supervised learning, we use <strong>annotated data</strong>, i.e.&nbsp;pairs <span class="math inline">\((x_i, t_i)\)</span> of input/output examples. This requires to know the ground truth for each sample, what can be be very tedious and expensive if humans have to do it.</p>
<p>In <strong>unsupervised learning</strong>, we only have inputs. The goal of the algorithms is to make sense out of the data: extract regularities, model the underlying distribution, group examples into clusters, etc… It may seem much harder than supervised learning, as there is no ground truth to measure performance, but data is very cheap to obtain.</p>
<section id="clustering-and-feature-extraction" class="level4" data-number="1.2.2.1">
<h4 data-number="1.2.2.1" class="anchored" data-anchor-id="clustering-and-feature-extraction"><span class="header-section-number">1.2.2.1</span> Clustering and feature extraction</h4>
<p><strong>Clustering</strong> is a classical machine technique allowing to group examples in clusters based on their respective distances: close examples should belong to the same cluster. The most well-know algorithms are k-means and Gaussian mixture models (GMM). But the quality of the clustering depends on the space in which the inputs are represented: two images may be similar not because their pixels are similar (e.g.&nbsp;two dark images), but because they contain similar objects (fishes, birds). Neural networks can be used to learn a <strong>feature space</strong> where distances between inputs are meaningful.</p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/unsupervised-learning.png</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 100%</td>
</tr>
</tbody>
</table>
<p>Clustering. Source: <a href="https://learn.g2.com/supervised-vs-unsupervised-learning" class="uri">https://learn.g2.com/supervised-vs-unsupervised-learning</a></p>
<pre><code>
#### Dimensionality reduction and autoencoders


Data such as images have a lot of dimensions (one per pixel), most of which are redundant. **Dimensionality reduction** techniques allow to reduce this number of dimensions by projecting the data into a **latent space** while keeping the information.

**Autoencoders** (AE) are neural networks that learn to reproduce their inputs (unsupervised learning, as there are no labels) by compressing information through a bottleneck. The **encoder** projects the input data onto the latent space, while the **decoder** recreates the input. The latent space has much less dimensions than the input images, but must contain enough information in order to reconstruct the image. 


```{figure} ../img/latent-space.png
---
width: 100%
---
Autoencoders. Source: &lt;https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694g&gt;</code></pre>
<p>Apart from compression, one important application of dimensionality reduction is <strong>visualization</strong> when the latent space has 2 or 3 dimensions: you can visualize the distribution of your data and estimate how hard the classification/regression will be. Classical ML techniques include PCA (principal component analysis) and t-SNE, but autoencoders can also be used, for example the <strong>UMAP</strong> (Uniform Manifold Approximation and Projection for Dimension Reduction) architecture {cite}<code>McInnes2020</code>.</p>
<p>Another application of autoencoders is the <strong>pretraining</strong> (feature extraction) of neural networks on unsupervised data before <strong>fine-tuning</strong> the resulting classifier on supervised data. This allows <strong>self-taught learning</strong> or <strong>semi-supervised learning</strong>, when the annotated data available for supervised learning is scarce, but a lot of unsupervised data from the same domain is available.</p>
</section>
<section id="generative-models" class="level4" data-number="1.2.2.2">
<h4 data-number="1.2.2.2" class="anchored" data-anchor-id="generative-models"><span class="header-section-number">1.2.2.2</span> Generative models</h4>
<p>The other major advantage of autoencoders is their <strong>decoder</strong>: from a low-dimensional latent representation, it is able after training to generate high-dimensional data such as images. By <strong>sampling</strong> the latent space, one could in principle generate an infinity of new images.</p>
<p>One particular form of autoencoder which is very useful for data generation is the <strong>variational autoencoder</strong> (VAE) {cite}<code>Kingma2013</code>. The main difference with a regular AE is that the latent encodes a <strong>probability distribution</strong> instead of a single latent vector, what allows to sample new but realistic outputs. For example, a VAE trained to reproduce faces can generate new hybrid faces depending on how the sampling is done:</p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/vae-faces.jpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 100%</td>
</tr>
</tbody>
</table>
<p>Sampling the latent space of a VAE trained on faces allows to generate new but realistic faces. Source: <a href="https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df" class="uri">https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df</a></p>
<pre><code>
VAE are in particular central to **DeepFakes** which have widely reached the media because of their impressive possibilities but also ethical issues:

&lt;div class='embed-container'&gt;&lt;iframe src='https://www.youtube.com/embed/JbzVhzNaTdI' frameborder='0' allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;

Another class of generative models are **generative adversarial networks** (GAN) {cite}`Goodfellow2014` which consist of a **generator** (decoder) and a **discriminator** that compete to produce realistic images while trying to discriminate generated from real images. 

```{figure} ../img/gan.jpg
---
width: 100%
---
Generative adversarial network.</code></pre>
<p>Several evolutions of GANs have allowed to produce increasingly realistic images, such as conditional GANs who permit to generate images of a desired class, or CycleGAN which allows to replace an object with another:</p>
<table class="table">
<thead>
<tr class="header">
<th>```{figure} ../img/cycleGAN4.jpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>width: 100%</td>
</tr>
</tbody>
</table>
<p>CycleGAN. <a href="https://github.com/junyanz/CycleGAN" class="uri">https://github.com/junyanz/CycleGAN</a></p>
<pre><code>
### Reinforcement learning

&lt;div class='embed-container'&gt;&lt;iframe src='https://www.youtube.com/embed/fczritSOcSM' frameborder='0' allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;

Reinforcement learning (RL) is not part of this module, as we offer a complete course on it:

&lt;https://www.tu-chemnitz.de/informatik/KI/edu/deeprl/&gt;

but it has recently gained a lot of importance when coupled with deep learning principles. Here we just present a couple of application of **deep reinforcement learning** to motivate you to also assist to this course. 

RL models the sequential interaction between an **agent** (algorithm, robot) and its **environment**. At each time step $t$, the agent is a state $s_t$ and selects an action $a_t$ according to its policy (or strategy) $\pi$. This brings the agent in a new state $s_{t+1}$ and provides a reward $r_{t+1}$. The reward is the only feedback that the agent receives about its action: when it is positive, it is good; when it is negative, it is bad. The goal of the of the agent is to maximize the sum of rewards that it receives **on the long-term**. For example in a video game, the states would correspond to each video frame, the actions are joystick movements and the rewards are scores increases and decreases. The goal is to move the joystick correctly so that the final cumulated score is maximal.


```{figure} ../img/rl-loop.png
---
width: 100%
---
Agent-environment interaction in RL. Source: &lt;https://ieeexplore.ieee.org/document/7839568&gt;</code></pre>
<p>In deep RL, the policy <span class="math inline">\(\pi\)</span> is implemented using a deep neural network whose job is to predict which action in a given state is the most likely to provide reward in the long-term. Contrary to supervised learning, we do not know which action should have been performed (ground truth), we only get rewards indicating if this was a good choice or not. This makes the learning problem much harder. But the deep RL methods are quite generic: any problem that can be described in terms of states, actions and rewards (formally, a Markov decision process) can be solved by deep RL techniques, at the cost of quite long training times. Let’s have a look at some applications:</p>
<ul>
<li>The first achievement of deep RL was the <strong>deep Q-network (DQN)</strong> of Deepmind able to solve a multitude of old Atari games from scratch using raw video inputs:</li>
</ul>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/rQIShnTz1kU" frameborder="0" allowfullscreen="">
</iframe>
</div>
<ul>
<li>Deep RL methods have since then been applied to more complex games, such as <strong>Starcraft II</strong>:</li>
</ul>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/UuhECwm31dM" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>or <strong>DotA 2</strong>:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/eHipy_j29Xw" frameborder="0" allowfullscreen="">
</iframe>
</div>
<ul>
<li>Another famous achievement of deep RL is when Google Deepmind’s <strong>AlphaGo</strong> beat Lee Sedol, 19 times world champion, in 2016:</li>
</ul>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/8tq1C8spV_g" frameborder="0" allowfullscreen="">
</iframe>
</div>
<ul>
<li>Deep RL is also a very promising to <strong>robotics</strong>, be it in simulation:</li>
</ul>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/faDKMMwOS2Q" frameborder="0" allowfullscreen="">
</iframe>
</div>
<p>or in reality:</p>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/jwSbzNHGflM" frameborder="0" allowfullscreen="">
</iframe>
</div>
<ul>
<li>It is also promising for <strong>autonomous driving</strong>:</li>
</ul>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/eRwTbRtnT1I" frameborder="0" allowfullscreen="">
</iframe>
</div>
</section>
</section>
</section>
<section id="outlook" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="outlook"><span class="header-section-number">1.3</span> Outlook</h2>
<div class="embed-container">
<iframe src="https://www.youtube.com/embed/KAE5mn7WFgU" frameborder="0" allowfullscreen="">
</iframe>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Course description</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notes/1.2-Math.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Math basics (optional)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>