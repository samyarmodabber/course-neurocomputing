[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurocomputing",
    "section": "",
    "text": "These are the lecture notes for the module Neurocomputing taught by Dr. Julien Vitay at the Technische Universität Chemnitz, Faculty of Computer Science, Professorship for Artificial Intelligence.\nEach section/lecture is accompanied by a set of videos, the slides and some lecture notes which summarize the most important points to understand. Some sections are optional in the sense that no questions will be asked at the exam, but those interested in becoming neural network experts should feel free to study them. The videos are integrated in the lecture notes, but you can also access the complete playlist on Youtube.\nExercises are provided in the form of Jupyter notebooks, allowing to implement in Python at your own pace the algorithms seen in the lectures and learn to use machine learning libraries such as scikit-learn, keras and tensorflow. A notebook to work on (locally or on Colab) and the solution are downloadable at the top of each page. A video explaining the exercise and one commenting the solution are available, with the playlist being on Youtube.\nRecommended readings:\n\n(Goodfellow et al., 2016) Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.deeplearningbook.org.\n(Haykin, 2009) Simon S. Haykin. Neural Networks and Learning Machines, 3rd Edition. Pearson, 2009. http://dai.fmph.uniba.sk/courses/NN/haykin.neural-networks.3ed.2009.pdf.\n(Chollet, 2017) François Chollet. Deep Learning with Python. Manning publications, 2017. https://www.manning.com/books/deep-learning-with-python.\n\n\n\n\n\nChollet, F. (2017). Deep Learning with Python. Manning publications.\n\n\nGoodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press.\n\n\nHaykin, S. S. (2009). Neural Networks and Learning Machines, 3rd Edition. Pearson."
  },
  {
    "objectID": "notes/1.1-Introduction.html",
    "href": "notes/1.1-Introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Slides: html pdf"
  },
  {
    "objectID": "notes/1.1-Introduction.html#what-is-neurocomputing",
    "href": "notes/1.1-Introduction.html#what-is-neurocomputing",
    "title": "1  Introduction",
    "section": "1.1 What is neurocomputing?",
    "text": "1.1 What is neurocomputing?\n\nLet’s first discuss the difference between Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) and Neurocomputing. Nowadays, these terms are used almost interchangeably, but there are historical and methodological differences.\n\n\n\nSource: https://data-science-blog.com/blog/2018/05/14/machine-learning-vs-deep-learning-wo-liegt-der-unterschied\n\n\nThe term Artificial Intelligence was coined by John McCarthy at the Dartmouth Summer Research Project on Artificial Intelligence in 1956:\n\nThe study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\n\nGood old-fashion AI (GOFAI) approaches were purely symbolic (logical systems, knowledge-based systems) or using linear neural networks. They were able to play checkers, prove mathematical theorems, make simple conversations (ELIZA), translate languages…\nMachine learning (ML) is a branch of AI that focuses on learning from examples (data-driven AI). It is sometimes also referred to as big data, data science, operational research, pattern recognition… ML algorithms include:\n\nArtificial Neural Networks (multi-layer perceptrons)\nStatistical analysis (Bayesian modeling, PCA)\nClustering algorithms (k-means, GMM, spectral clustering)\nSupport vector machines\nDecision trees, random forests\n\nDeep Learning is a recent re-branding of artificial neural networks. It focuses on learning high-level representations of the data, using highly non-linear neural networks. Many architectures have been developped, including:\n\nDeep neural networks (DNN)\nConvolutional neural networks (CNN)\nRecurrent neural networks (RNN)\nGenerative models (GAN, VAE)\nDeep reinforcement learning (DQN, PPO, AlphaGo)\nTransformers\nGraph neural networks\n\n\nNeurocomputing is at the intersection between computational neuroscience and artificial neural networks (deep learning). Computational neuroscience studies the functioning of the brain (human or animal) through biologically detailed models, either at the functional level (e.g. visual attention, decision-making) or cellular level (individual neurons, synapses, neurotransmitters, etc). The goal of computational neuroscience is 1) to provide theoretical explanations to the experimental observations made by neuroscientists and 2) make predictions that can be verified experimentally. Moreover, understanding how the brain solves real-life problems might allow to design better AI algorithms. If you are interested in computational neuroscience, make sure to visit the courses Neurokognition I and II taught by Prof. Dr. Hamker:\nhttps://www.tu-chemnitz.de/informatik/KI/edu/neurokognition/\nNeurocomputing aims at bringing the mechanisms underlying human cognition into artificial intelligence. The first part of this course focuses on deep learning, while the second will discuss how more biologically realistic neural networks could help designing better AI systems."
  },
  {
    "objectID": "notes/1.1-Introduction.html#applications-of-deep-learning",
    "href": "notes/1.1-Introduction.html#applications-of-deep-learning",
    "title": "1  Introduction",
    "section": "1.2 Applications of deep learning",
    "text": "1.2 Applications of deep learning\nMachine Learning applications are generally divided into three main branches:\n\nSupervised learning: The program is trained on a pre-defined set of training examples and used to make correct predictions when given new data.\nUnsupervised learning: The program is given a bunch of data and must find patterns and relationships therein.\nReinforcement learning: The program explores its environment by producing actions and receiving rewards.\n\n\n\n\nSource: http://www.isaziconsulting.co.za/machinelearning.html\n\n\nDeep learning has recently revolutionized these types of machine learning, so let’s have a look at some concrete examples for motivation. At the end of the course, if you also perform all exercises, you should be able to reproduce these applications.\n\n1.2.1 Supervised learning\n\n\n\n\nPrinciple of supervised learning. Source: Andrew Ng, Stanford CS229, https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf\n\n\nIn a supervised learning, we have a training set (or training data) consisting of \\(N\\) samples (or examples) from which we want to learn the underlying function or distribution. Each sample consists of an input \\(\\mathbf{x}_i\\) and an output (also called ground truth, desired output or target) \\(t_i\\).\nWhat we want to learn is parameterized model \\(y_i = f_\\theta (\\mathbf{x}_i)\\) which can predict the correct output for the inputs of the training set. The goal of learning (or training) is to find which value of the parameters \\(\\theta\\) allows to reduce (minimize) the prediction error. i.e. the discrepancy between the prediction \\(y_i = f_\\theta (\\mathbf{x}_i)\\) and the desired output \\(t_i\\).\nDepending on the nature of the outputs \\(t\\), we have two different supervised problems:\n\nIn regression tasks, the outputs can take an infinity of values (e.g. real numbers). The following figure shows how examples of flat surfaces (input \\(x_i\\)) and prices (output \\(t_i\\)) collected in the neighborhood can be used to predict the price of a new flat. After collecting enough samples, a model is trained to minimize its prediction error. Here, a linear model is used (black line) as we perform linear regression, but any other type of function could be used. The parameters of the line (slope and intercept) are adapted so that the line lies close to the data: the predicted price \\(y_i\\) is never far from the ground truth \\(t_i\\). Using that line after learning, we can predict that a 60 square meters flat should be rented around 550 euros/month.\n\n\n\n\n````{figure} ../img/regression-animation3.png\n\n\n\n\nwidth: 80%\n\n\n\n\n* In **classification** tasks, the outputs are discrete, i.e. take only a finite number of different values (called classes or labels). When there are only two classes, they are called the positive and negative classes and the problem is a **binary classification**. The two classes can represent yes/no binary values, such as when when a test is positive or negative. When there are more than two classes, they can for example represent different objects (car / bike / dog / cat...) that can be recognized on an image. The following figure depicts a binary classifiation problem, where two input features $x_1$ and $x_2$ (temperature and blood pressure) are used to predict the occurence of an illness (yes = ill, no = sane). The linear model is a line that separates the input space into two separate regions: all points above the line are categorized (classified) as ill, all points below as sane, even if they were not in the training data.\n\n````{figure} ../img/classification-animation3.png\n---\nwidth: 80%\n---\nIn practice, when using neural networks, the distinction between classification and regression is not very important, but it can be relevant for other ML techniques (decision trees only work for classification problems, for example).\n\n1.2.1.1 Feedforward neural networks\nAs we will see later, an artificial neuron is a mathematical model able to perform linear classification or regression using weighted sums of inputs:\n\\[y = f(\\sum_{i=1}^d w_i \\, x_i + b)\\]\n\n\n\n```{figure} ../img/artificialneuron.svg\n\n\n\n\nwidth: 60%\n\n\n\nArtificial neuron.\n\nBy stacking layers of artificial neurons, we obtain a **feedforward neural network** able to solve non-linear classification and regression problems.\n\n```{figure} ../img/deep.svg\n---\nwidth: 60%\n---\nFeedforward neural network.\nFully-connected layers of neurons can be replaced by convolutional layers when dealing with images as inputs, leading to the very successful convolutional neural networks (CNN).\n\n\n\n```{figure} ../img/dcn.png\n\n\n\n\nwidth: 90%\n\n\n\nTypical CNN architecture. Source: Albelwi S, Mahmood A. 2017. A Framework for Designing the Architectures of Deep Convolutional Neural Networks. Entropy 19:242. doi:10.3390/e19060242\n\nThe \"only\" thing to do is to feed these networks with a lot of training data (inputs and desired outputs) and let them adjust their weights to minimize their prediction error using the backpropagation algorithm {cite}`Rumelhart1986a` (more on that later). Neural networks (including CNNs) are a very old technology, dating back from the 60's, with a resurgence in the 80's thanks to the backpropation algorithm. They had been able to learn small datasets, but their performance was limited by the availability of data and the computing power available at the time. One classical example is the use of a CNN {cite}`LeCun1998` by Yann LeCun in 1998 to automatically classify single digits on ZIP postal codes (what led to the development of the MNIST dataset, the \"Hello World!\" of machine learning which we will use in the exercises). \n\n```{figure} ../img/lenet5.gif\n---\nwidth: 50%\n---\nLeNet5 CNN trained on MNIST. Source: <http://yann.lecun.com/exdb/lenet/>\nThe revival of artificial neural networks marketed as deep learning at the end of the 2000’s was principally due the availability of massive amounts of training data (thanks to search engines and social networks) and the availability of consumer graphics GPUs able to perform scientific computations, especially using Nvidia’s CUDA programming framework.\nThe first badge of honour obtained by deep learning methods happened during the ImageNet challenge in 2012. The challenge was made for computer vision (CV) scientists to compare their algorithms on a huge dataset of 14 billion annotated images for object recognition (what is on the image?), object detection (which objects are in the image and where?) and object segmentation (which pixels belong to which object?). The object recognition challenge was indeed quite hard, with 1000 different classes (sometimes exotic, such as “ladle” or “porcupine”) with a great variety of backgrounds or lightning conditions. Classical CV methods based on feature extraction and simple classifiers performed reasonably well, with an error rate around 30%.\nHowever, Krizhevsky, Sutskever and Hinton {cite}Krizhevsky2012 trained a CNN entirely on the images, without any form of preprocessing, and obtained an error rate of 15%, half of the other methods. This achievement marked the beginning of the deep learning era, attracted the attention of the major industrial players (Google, Facebook and soon the rest of the world) who have already invested hundreds of billions on AI research.\nThe whole field of computer vision was taken by storm, and CNNs were able to outperform the state-of-the-art of many vision-related tasks, such as object detection with the YOLO (You Only Look Once) network {cite}Redmon2016:\n\n\n\n\nor semantic segmention with SegNet {cite}Badrinarayanan2016 or its variants such as Mask RCNN {cite}He2018:\n\n\n\n\nCNNs can even be used to control autonomous cars, by learning to reproduce human commands for a given input image {cite}Bojarski2016:\n\n\n\n\nCNNs are also gaining an increasing importance in medical applications, for example to help histologists detect cancerous cells:\n\n\n\n\n\n\n1.2.1.2 Recurrent neural networks\n\n\n\n\nAnother field that was heavily transformed by deep learning is natural language processing (NLP), i.e. the automatic processing of language, be it text understanding, translation, summarization, question answering or even speech recognition and synthesis. In short, everything needed under the hood when you talk to Siri or Alexa.\nThe key neural network involved in this paradigmatic change is the recurrent neural network (RNN), with the most prominent model being the long short-term memory (LSTM) network {cite}Hochreiter1997.\n\n\n\n```{figure} ../img/LSTM3-chain.png\n\n\n\n\nwidth: 90%\n\n\n\nLSTM cell. Source: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n\nThe main difference with feedforward neural networks is that RNNs can be applied on sequences (of words, but it could also be video frames or any time-dependent signal). At each step, a RNN produces an output not only depending on its current input, but also on its previous output, implementing a form of memory of past events. \n\nMore recent advances furthermore introduce the concept of **attention** for processing sequences. This is now at the heart of all translation systems or in BERT, the language understanding module behind Google search. The neural architectures may seem complex, but we will break them down in this course.\n\n```{figure} ../img/google-nmt-lstm.png\n---\nwidth: 100%\n---\nGoogle Neural Machine Translation. Source: <https://ai.google/research/pubs/pub45610>\n\n\n\n1.2.2 Unsupervised learning\n\n\n\n\nIn supervised learning, we use annotated data, i.e. pairs \\((x_i, t_i)\\) of input/output examples. This requires to know the ground truth for each sample, what can be be very tedious and expensive if humans have to do it.\nIn unsupervised learning, we only have inputs. The goal of the algorithms is to make sense out of the data: extract regularities, model the underlying distribution, group examples into clusters, etc… It may seem much harder than supervised learning, as there is no ground truth to measure performance, but data is very cheap to obtain.\n\n1.2.2.1 Clustering and feature extraction\nClustering is a classical machine technique allowing to group examples in clusters based on their respective distances: close examples should belong to the same cluster. The most well-know algorithms are k-means and Gaussian mixture models (GMM). But the quality of the clustering depends on the space in which the inputs are represented: two images may be similar not because their pixels are similar (e.g. two dark images), but because they contain similar objects (fishes, birds). Neural networks can be used to learn a feature space where distances between inputs are meaningful.\n\n\n\n```{figure} ../img/unsupervised-learning.png\n\n\n\n\nwidth: 100%\n\n\n\nClustering. Source: https://learn.g2.com/supervised-vs-unsupervised-learning\n\n#### Dimensionality reduction and autoencoders\n\n\nData such as images have a lot of dimensions (one per pixel), most of which are redundant. **Dimensionality reduction** techniques allow to reduce this number of dimensions by projecting the data into a **latent space** while keeping the information.\n\n**Autoencoders** (AE) are neural networks that learn to reproduce their inputs (unsupervised learning, as there are no labels) by compressing information through a bottleneck. The **encoder** projects the input data onto the latent space, while the **decoder** recreates the input. The latent space has much less dimensions than the input images, but must contain enough information in order to reconstruct the image. \n\n\n```{figure} ../img/latent-space.png\n---\nwidth: 100%\n---\nAutoencoders. Source: <https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694g>\nApart from compression, one important application of dimensionality reduction is visualization when the latent space has 2 or 3 dimensions: you can visualize the distribution of your data and estimate how hard the classification/regression will be. Classical ML techniques include PCA (principal component analysis) and t-SNE, but autoencoders can also be used, for example the UMAP (Uniform Manifold Approximation and Projection for Dimension Reduction) architecture {cite}McInnes2020.\nAnother application of autoencoders is the pretraining (feature extraction) of neural networks on unsupervised data before fine-tuning the resulting classifier on supervised data. This allows self-taught learning or semi-supervised learning, when the annotated data available for supervised learning is scarce, but a lot of unsupervised data from the same domain is available.\n\n\n1.2.2.2 Generative models\nThe other major advantage of autoencoders is their decoder: from a low-dimensional latent representation, it is able after training to generate high-dimensional data such as images. By sampling the latent space, one could in principle generate an infinity of new images.\nOne particular form of autoencoder which is very useful for data generation is the variational autoencoder (VAE) {cite}Kingma2013. The main difference with a regular AE is that the latent encodes a probability distribution instead of a single latent vector, what allows to sample new but realistic outputs. For example, a VAE trained to reproduce faces can generate new hybrid faces depending on how the sampling is done:\n\n\n\n```{figure} ../img/vae-faces.jpg\n\n\n\n\nwidth: 100%\n\n\n\nSampling the latent space of a VAE trained on faces allows to generate new but realistic faces. Source: https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df\n\nVAE are in particular central to **DeepFakes** which have widely reached the media because of their impressive possibilities but also ethical issues:\n\n<div class='embed-container'><iframe src='https://www.youtube.com/embed/JbzVhzNaTdI' frameborder='0' allowfullscreen></iframe></div>\n\nAnother class of generative models are **generative adversarial networks** (GAN) {cite}`Goodfellow2014` which consist of a **generator** (decoder) and a **discriminator** that compete to produce realistic images while trying to discriminate generated from real images. \n\n```{figure} ../img/gan.jpg\n---\nwidth: 100%\n---\nGenerative adversarial network.\nSeveral evolutions of GANs have allowed to produce increasingly realistic images, such as conditional GANs who permit to generate images of a desired class, or CycleGAN which allows to replace an object with another:\n\n\n\n```{figure} ../img/cycleGAN4.jpg\n\n\n\n\nwidth: 100%\n\n\n\nCycleGAN. https://github.com/junyanz/CycleGAN\n\n### Reinforcement learning\n\n<div class='embed-container'><iframe src='https://www.youtube.com/embed/fczritSOcSM' frameborder='0' allowfullscreen></iframe></div>\n\nReinforcement learning (RL) is not part of this module, as we offer a complete course on it:\n\n<https://www.tu-chemnitz.de/informatik/KI/edu/deeprl/>\n\nbut it has recently gained a lot of importance when coupled with deep learning principles. Here we just present a couple of application of **deep reinforcement learning** to motivate you to also assist to this course. \n\nRL models the sequential interaction between an **agent** (algorithm, robot) and its **environment**. At each time step $t$, the agent is a state $s_t$ and selects an action $a_t$ according to its policy (or strategy) $\\pi$. This brings the agent in a new state $s_{t+1}$ and provides a reward $r_{t+1}$. The reward is the only feedback that the agent receives about its action: when it is positive, it is good; when it is negative, it is bad. The goal of the of the agent is to maximize the sum of rewards that it receives **on the long-term**. For example in a video game, the states would correspond to each video frame, the actions are joystick movements and the rewards are scores increases and decreases. The goal is to move the joystick correctly so that the final cumulated score is maximal.\n\n\n```{figure} ../img/rl-loop.png\n---\nwidth: 100%\n---\nAgent-environment interaction in RL. Source: <https://ieeexplore.ieee.org/document/7839568>\nIn deep RL, the policy \\(\\pi\\) is implemented using a deep neural network whose job is to predict which action in a given state is the most likely to provide reward in the long-term. Contrary to supervised learning, we do not know which action should have been performed (ground truth), we only get rewards indicating if this was a good choice or not. This makes the learning problem much harder. But the deep RL methods are quite generic: any problem that can be described in terms of states, actions and rewards (formally, a Markov decision process) can be solved by deep RL techniques, at the cost of quite long training times. Let’s have a look at some applications:\n\nThe first achievement of deep RL was the deep Q-network (DQN) of Deepmind able to solve a multitude of old Atari games from scratch using raw video inputs:\n\n\n\n\n\n\nDeep RL methods have since then been applied to more complex games, such as Starcraft II:\n\n\n\n\n\nor DotA 2:\n\n\n\n\n\nAnother famous achievement of deep RL is when Google Deepmind’s AlphaGo beat Lee Sedol, 19 times world champion, in 2016:\n\n\n\n\n\n\nDeep RL is also a very promising to robotics, be it in simulation:\n\n\n\n\n\nor in reality:\n\n\n\n\n\nIt is also promising for autonomous driving:"
  },
  {
    "objectID": "notes/1.1-Introduction.html#outlook",
    "href": "notes/1.1-Introduction.html#outlook",
    "title": "1  Introduction",
    "section": "1.3 Outlook",
    "text": "1.3 Outlook"
  },
  {
    "objectID": "notes/1.2-Math.html",
    "href": "notes/1.2-Math.html",
    "title": "2  Math basics (optional)",
    "section": "",
    "text": "Slides: html pdf\nThis chapter is not part of the course itself (there will not be questions at the exam on basic mathematics) but serves as a reminder of the important mathematical notions that are needed to understand this course. Students who have studied mathematics as a major can safely skip this part, as there is nothing fancy (although the section on information theory could be worth a read).\nIt is not supposed to replace any course in mathematics (we won’t show any proof and will skip what we do not need) but rather to provide a high-level understanding of the most important concepts and set the notations. Nothing should be really new to you, but it may be useful to have everything summarized at the same place.\nReferences: Part I of Goodfellow et al. (2016). Any mathematics textbook can be used in addition."
  },
  {
    "objectID": "notes/1.2-Math.html#linear-algebra",
    "href": "notes/1.2-Math.html#linear-algebra",
    "title": "2  Math basics (optional)",
    "section": "2.1 Linear algebra",
    "text": "2.1 Linear algebra\n\nSeveral mathematical objects are manipulated in linear algebra:\n\nScalars \\(x\\) are 0-dimensional values (single numbers, so to speak). They can either take real values (\\(x \\in \\Re\\), e.g. \\(x = 1.4573\\), floats in CS) or natural values (\\(x \\in \\mathbb{N}\\), e.g. \\(x = 3\\), integers in CS).\nVectors \\(\\mathbf{x}\\) are 1-dimensional arrays of length \\(d\\). The bold notation \\(\\mathbf{x}\\) will be used in this course, but you may also be accustomed to the arrow notation \\(\\overrightarrow{x}\\) used on the blackboard. When using real numbers, the vector space with \\(d\\) dimensions is noted \\(\\Re^d\\), so we can note \\(\\mathbf{x} \\in \\Re^d\\). Vectors are typically represented vertically to outline their \\(d\\) elements \\(x_1, x_2, \\ldots, x_d\\):\n\n\\[\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix}\\]\n\nMatrices \\(A\\) are 2-dimensional arrays of size (or shape) \\(m \\times n\\) (\\(m\\) rows, \\(n\\) columns, \\(A \\in \\Re^{m \\times n}\\)). They are represented by a capital letter to distinguish them from scalars (classically also in bold \\(\\mathbf{A}\\) but not here). The element \\(a_{ij}\\) of a matrix \\(A\\) is the element on the \\(i\\)-th row and \\(j\\)-th column.\n\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n\\end{bmatrix}\\]\n\nTensors \\(\\mathcal{A}\\) are arrays with more than two dimensions. We will not really do math on these objects, but they are useful internally (hence the name of the tensorflow library).\n\n\n2.1.1 Vectors\nA vector can be thought of as the coordinates of a point in an Euclidean space (such the 2D space), relative to the origin. A vector space relies on two fundamental operations, which are that:\n\nVectors can be added:\n\n\\[\\mathbf{x} + \\mathbf{y} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix} + \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_d \\end{bmatrix} = \\begin{bmatrix} x_1 + y_1 \\\\ x_2 + y_2 \\\\ \\vdots \\\\ x_d + y_d \\end{bmatrix}\\]\n\nVectors can be multiplied by a scalar:\n\n\\[a \\, \\mathbf{x} = a \\, \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix} = \\begin{bmatrix} a \\, x_1 \\\\ a \\, x_2 \\\\ \\vdots \\\\ a \\, x_d \\end{bmatrix}\\]\n\n\n\nVector spaces allow additions of vectors. Source: https://mathinsight.org/image/vector_2d_add\n\n\nThese two operations generate a lot of nice properties (see https://en.wikipedia.org/wiki/Vector_space for a full list), including:\n\nassociativity: \\(\\mathbf{x} + (\\mathbf{y} + \\mathbf{z}) = (\\mathbf{x} + \\mathbf{y}) + \\mathbf{z}\\)\ncommutativity: \\(\\mathbf{x} + \\mathbf{y} = \\mathbf{y} + \\mathbf{x}\\)\nthe existence of a zero vector \\(\\mathbf{x} + \\mathbf{0} = \\mathbf{x}\\)\ninversion: \\(\\mathbf{x} + (-\\mathbf{x}) = \\mathbf{0}\\)\ndistributivity: \\(a \\, (\\mathbf{x} + \\mathbf{y}) = a \\, \\mathbf{x} + a \\, \\mathbf{y}\\)\n\nVectors have a norm (or length) \\(||\\mathbf{x}||\\). The most intuitive one (if you know the Pythagoras theorem) is the Euclidean norm or \\(L^2\\)-norm, which sums the square of each element:\n\\[||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\]\nOther norms exist, distinguished by the subscript. The \\(L^1\\)-norm (also called Taxicab or Manhattan norm) sums the absolute value of each element:\n\\[||\\mathbf{x}||_1 = |x_1| + |x_2| + \\ldots + |x_d|\\]\nThe p-norm generalizes the Euclidean norm to other powers \\(p\\):\n\\[||\\mathbf{x}||_p = (|x_1|^p + |x_2|^p + \\ldots + |x_d|^p)^{\\frac{1}{p}}\\]\nThe infinity norm (or maximum norm) \\(L^\\infty\\) returns the maximum element of the vector:\n\\[||\\mathbf{x}||_\\infty = \\max(|x_1|, |x_2|, \\ldots, |x_d|)\\]\nOne important operation for vectors is the dot product (also called scalar product or inner product) between two vectors:\n\\[\\langle \\mathbf{x} \\cdot \\mathbf{y} \\rangle = \\langle \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix} \\cdot \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_d \\end{bmatrix} \\rangle = x_1 \\, y_1 + x_2 \\, y_2 + \\ldots + x_d \\, y_d\\]\nThe dot product basically sums one by one the product of the elements of each vector. The angular brackets are sometimes omitted (\\(\\mathbf{x} \\cdot \\mathbf{y}\\)) but we will use them in this course for clarity.\nOne can notice immediately that the dot product is symmetric:\n\\[\\langle \\mathbf{x} \\cdot \\mathbf{y} \\rangle = \\langle \\mathbf{y} \\cdot \\mathbf{x} \\rangle\\]\nand linear:\n\\[\\langle (a \\, \\mathbf{x} + b\\, \\mathbf{y}) \\cdot \\mathbf{z} \\rangle = a\\, \\langle \\mathbf{x} \\cdot \\mathbf{z} \\rangle + b \\, \\langle \\mathbf{y} \\cdot \\mathbf{z} \\rangle\\]\nThe dot product is an indirect measurement of the angle \\(\\theta\\) between two vectors:\n\\[\\langle \\mathbf{x} \\cdot \\mathbf{y} \\rangle = ||\\mathbf{x}||_2 \\, ||\\mathbf{y}||_2 \\, \\cos(\\theta)\\]\n\n\n\n```{figure} ../img/dotproduct.png\n\n\n\n\nwidth: 50%\n\n\n\nThe dot product between two vectors is proportional to the cosine of the angle between the two vectors. Source: https://en.wikipedia.org/wiki/Dot_product\n\nIf you normalize the two vectors by dividing them by their norm (which is a scalar), we indeed have the cosine of the angle between them: The higher the normalized dot product, the more the two vectors point towards the same direction (**cosine distance** between two vectors).\n\n\n$$\\langle \\displaystyle\\frac{\\mathbf{x}}{||\\mathbf{x}||_2} \\cdot \\frac{\\mathbf{y}}{||\\mathbf{y}||_2} \\rangle =  \\cos(\\theta)$$\n\n### Matrices\n\nMatrices are derived from vectors, so most of the previous properties will be true. Let's consider this 4x3 matrix:\n\n$$A = \\begin{bmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33} \\\\\na_{41} & a_{42} & a_{43} \\\\\n\\end{bmatrix}$$\n\nEach column of the matrix is a vector with 4 elements:\n\n$$\\mathbf{a}_1 = \\begin{bmatrix}\na_{11} \\\\\na_{21} \\\\\na_{31} \\\\\na_{41} \\\\\n\\end{bmatrix} \\qquad\n\\mathbf{a}_2 = \\begin{bmatrix}\na_{12} \\\\\na_{22} \\\\\na_{32} \\\\\na_{42} \\\\\n\\end{bmatrix} \\qquad\n\\mathbf{a}_3 = \\begin{bmatrix}\na_{13} \\\\\na_{23} \\\\\na_{33} \\\\\na_{43} \\\\\n\\end{bmatrix} \\qquad\n$$\n\nA $m \\times n$ matrix is therefore a collection of $n$ vectors of size $m$ put side by side column-wise:\n\n$$A = \\begin{bmatrix}\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\mathbf{a}_3\\\\\n\\end{bmatrix}$$\n\nSo all properties of the vector spaces (associativity, commutativity, distributivity) also apply to matrices, as additions and multiplications with a scalar are defined.\n\n$$\\alpha \\, A + \\beta \\, B = \\begin{bmatrix}\n\\alpha\\, a_{11} + \\beta \\, b_{11} & \\alpha\\, a_{12} + \\beta \\, b_{12} & \\alpha\\, a_{13} + \\beta \\, b_{13} \\\\\n\\alpha\\, a_{21} + \\beta \\, b_{21} & \\alpha\\, a_{22} + \\beta \\, b_{22} & \\alpha\\, a_{23} + \\beta \\, b_{23} \\\\\n\\alpha\\, a_{31} + \\beta \\, b_{31} & \\alpha\\, a_{32} + \\beta \\, b_{32} & \\alpha\\, a_{33} + \\beta \\, b_{33} \\\\\n\\alpha\\, a_{41} + \\beta \\, b_{41} & \\alpha\\, a_{42} + \\beta \\, b_{42} & \\alpha\\, a_{43} + \\beta \\, b_{43} \\\\\n\\end{bmatrix}$$\n\n\n\n```{note}\nBeware, you can only add matrices of the same dimensions $m\\times n$. You cannot add a $2\\times 3$ matrix to a $5 \\times 4$ one.\nThe transpose \\(A^T\\) of a \\(m \\times n\\) matrix \\(A\\) is a \\(n \\times m\\) matrix, where the row and column indices are swapped:\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n\\end{bmatrix}, \\qquad\nA^T = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn} \\\\\n\\end{bmatrix}\n\\]\nThis is also true for vectors, which become horizontal after transposition:\n\\[\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix}, \\qquad\n\\mathbf{x}^T = \\begin{bmatrix} x_1 & x_2 & \\ldots & x_d \\end{bmatrix}\n\\]\nA very important operation is the matrix multiplication. If \\(A\\) is a \\(m\\times n\\) matrix and \\(B\\) a \\(n \\times p\\) matrix:\n\\[\nA=\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n\\end{bmatrix},\\quad\nB=\\begin{bmatrix}\nb_{11} & b_{12} & \\cdots & b_{1p} \\\\\nb_{21} & b_{22} & \\cdots & b_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nb_{n1} & b_{n2} & \\cdots & b_{np} \\\\\n\\end{bmatrix}\n\\]\nwe can multiply them to obtain a \\(m \\times p\\) matrix:\n\\[\nC = A \\times B =\\begin{bmatrix}\nc_{11} & c_{12} & \\cdots & c_{1p} \\\\\nc_{21} & c_{22} & \\cdots & c_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nc_{m1} & c_{m2} & \\cdots & c_{mp} \\\\\n\\end{bmatrix}\n\\]\nwhere each element \\(c_{ij}\\) is the dot product of the \\(i\\)th row of \\(A\\) and \\(j\\)th column of \\(B\\):\n\\[c_{ij} = \\langle A_{i, :} \\cdot B_{:, j} \\rangle = a_{i1}b_{1j} + a_{i2}b_{2j} +\\cdots + a_{in}b_{nj}= \\sum_{k=1}^n a_{ik}b_{kj}\\]\n$n$, the number of columns of $A$ and rows of $B$, must be the same!\n\n\n\n```{figure} ../img/matrixmultiplication.jpg\n\n\n\n\nwidth: 60%\n\n\n\nThe element \\(c_{ij}\\) of \\(C = A \\times B\\) is the dot product between the \\(i\\)th row of \\(A\\) and the \\(j\\)th column of \\(B\\). Source: https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Book%3A_Mathematical_Methods_in_Chemistry_(Levitus)/15%3A_Matrices/15.03%3A_Matrix_Multiplication CC BY-NC-SA; Marcia Levitus\n\nThinking of vectors as $n \\times 1$ matrices, we can multiply a matrix $m \\times n$ with a vector:\n\n$$\n\\mathbf{y} = A \\times \\mathbf{x} = \\begin{bmatrix}\n a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\\n\\end{bmatrix} \\times \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\n$$\n\nThe result $\\mathbf{y}$ is a vector of size $m$. In that sense, a matrix $A$ can transform a vector of size $n$ into a vector of size $m$: $A$ represents a **projection** from $\\Re^n$ to $\\Re^m$.\n\n```{figure} ../img/projection.png\n---\nwidth: 60%\n---\nA $2 \\times 3$ projection matrix allows to project any 3D vector onto a 2D plane. This is for example what happens inside a camera. Source: <https://en.wikipedia.org/wiki/Homogeneous_coordinate>\nNote that the dot product between two vectors of size \\(n\\) is the matrix multiplication between the transpose of the first vector and the second one:\n\\[\\mathbf{x}^T \\times \\mathbf{y} = \\begin{bmatrix} x_1 & x_2 & \\ldots & x_n \\end{bmatrix} \\times \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} = x_1 \\, y_1 + x_2 \\, y_2 + \\ldots + x_n \\, y_n = \\langle \\mathbf{x} \\cdot \\mathbf{y} \\rangle\\]\nSquare matrices of size \\(n \\times n\\) can be inverted. The inverse \\(A^{-1}\\) of a matrix \\(A\\) is defined by:\n\\[A \\times A^{-1} = A^{-1} \\times A = I\\]\nwhere \\(I\\) is the identity matrix (a matrix with ones on the diagonal and 0 otherwise). Not all matrices have an inverse (those who don’t are called singular or degenerate). There are plenty of conditions for a matrix to be invertible (for example its determinant is non-zero, see https://en.wikipedia.org/wiki/Invertible_matrix), but they will not matter in this course. Non-square matrices are generally not invertible, but see the pseudoinverse (https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse).\nMatrix inversion allows to solve linear systems of equations. Given the problem:\n\\[\n\\begin{cases}\n    a_{11} \\, x_1 + a_{12} \\, x_2 + \\ldots + a_{1n} \\, x_n = b_1 \\\\\n    a_{21} \\, x_1 + a_{22} \\, x_2 + \\ldots + a_{2n} \\, x_n = b_2 \\\\\n    \\ldots \\\\\n    a_{n1} \\, x_1 + a_{n2} \\, x_2 + \\ldots + a_{nn} \\, x_n = b_n \\\\\n\\end{cases}\n\\]\nwhich is equivalent to:\n\\[A \\times \\mathbf{x} = \\mathbf{b}\\]\nwe can multiply both sides to the left with \\(A^{-1}\\) (if it exists) and obtain:\n\\[\\mathbf{x} = A^{-1} \\times \\mathbf{b}\\]"
  },
  {
    "objectID": "notes/1.2-Math.html#calculus",
    "href": "notes/1.2-Math.html#calculus",
    "title": "2  Math basics (optional)",
    "section": "2.2 Calculus",
    "text": "2.2 Calculus\n\n\n\n\n\n2.2.1 Functions\nA univariate function \\(f\\) associates to any real number \\(x \\in \\Re\\) (or a subset of \\(\\Re\\) called the support of the function) another (unique) real number \\(f(x)\\):\n\\[\n\\begin{align}\nf\\colon \\quad \\Re &\\to \\Re\\\\\nx &\\mapsto f(x),\\end{align}\n\\]\n\n\n\n```{figure} ../img/function.png\n\n\n\n\nwidth: 60%\n\n\n\nExample of univariate function, here the quadratic function \\(f(x) = x^2 - 2 \\, x + 1\\).\n\n\nA **multivariate function** $f$ associates to any vector $\\mathbf{x} \\in \\Re^n$ (or a subset) a real number $f(\\mathbf{x})$:\n\n$$\n\\begin{align}\nf\\colon \\quad \\Re^n &\\to \\Re\\\\\n\\mathbf{x} &\\mapsto f(\\mathbf{x}),\\end{align}\n$$\n\nThe variables of the function are the elements of the vector. For low-dimensional vector spaces, it is possible to represent each element explicitly, for example:\n\n$$\n\\begin{align}\nf\\colon \\quad\\Re^3 &\\to \\Re\\\\\nx, y, z &\\mapsto f(x, y, z),\\end{align}\n$$\n\n```{figure} ../img/multivariatefunction.png\n---\nwidth: 60%\n---\nExample of a multivariate function $f(x_1, x_2)$ mapping $\\Re^2$ to $\\Re$. Source: <https://en.wikipedia.org/wiki/Function_of_several_real_variables>\nVector fields associate to any vector \\(\\mathbf{x} \\in \\Re^n\\) (or a subset) another vector (possibly of different size):\n\\[\n\\begin{align}\n\\overrightarrow{f}\\colon \\quad \\Re^n &\\to \\Re^m\\\\\n\\mathbf{x} &\\mapsto \\overrightarrow{f}(\\mathbf{x}),\\end{align}\n\\]\n\n\n\n```{figure} ../img/vectorfield.png\n\n\n\n\nwidth: 40%\n\n\n\nVector field associating to each point of \\(\\Re^2\\) another vector. Source: https://en.wikipedia.org/wiki/Vector_field\n\n\n\n```{note}\nThe matrix-vector multiplication $\\mathbf{y} = A \\times \\mathbf{x}$ is a linear vector field, mapping any vector $\\mathbf{x}$ into another vector $\\mathbf{y}$.\n\n\n2.2.2 Differentiation\n\n2.2.2.1 Derivatives\nDifferential calculus deals with the derivative of a function, a process called differentiation.\nThe derivative \\(f'(x)\\) or \\(\\displaystyle\\frac{d f(x)}{dx}\\) of a univariate function \\(f(x)\\) is defined as the local slope of the tangent to the function for a given value of \\(x\\):\n\\[f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\\]\nThe line passing through the points \\((x, f(x))\\) and \\((x + h, f(x + h))\\) becomes tangent to the function when \\(h\\) becomes very small:\n\n\n\n```{figure} ../img/derivative-approx.png\n\n\n\n\nwidth: 60%\n\n\n\nThe derivative of the function \\(f(x)\\) can be approximated by the slope of the line passing through \\((x, f(x))\\) and \\((x + h, f(x + h))\\) when \\(h\\) becomes very small.\n\nThe sign of the derivative tells you how the function behaves locally:\n\n* If the derivative is positive, increasing a little bit $x$ increases the function $f(x)$, so the function is **locally increasing**.\n* If the derivative is negative, increasing a little bit $x$ decreases the function $f(x)$, so the function is **locally decreasing**.\n\nIt basically allows you to measure the local influence of $x$ on $f(x)$: if I change a little bit the value $x$, what happens to $f(x)$? This will be very useful in machine learning.\n\nA special case is when the derivative is equal to 0 in $x$. $x$ is then called an **extremum** (or optimum) of the function, i.e. it can be a maximum or minimum. \n\n\n\n```{note}\nIf you differentiate $f'(x)$ itself, you obtain the **second-order derivative** $f''(x)$. You can repeat that process and obtain higher order derivatives. \n\nFor example, if $x(t)$ represents the position $x$ of an object depending on time $t$, the first-order derivative $x'(t)$ denotes the **speed** of the object and the second-order derivative $x''(t)$ its **acceleration**.\nYou can tell whether an extremum is a maximum or a minimum by looking at its second-order derivative:\n\nIf \\(f''(x) > 0\\), the extremum is a minimum.\nIf \\(f''(x) < 0\\), the extremum is a maximum.\nIf \\(f''(x) = 0\\), the extremum is a saddle point.\n\n\n\n\n```{figure} ../img/optimization-example.png\n\n\n\n\nwidth: 80%\n\n\n\nQuadratic functions have only one extremum (here a minimum in -1), as their derivative is linear and is equal to zero for only one value.\n\nThe derivative of a **multivariate function** $f(\\mathbf{x})$ is a vector of partial derivatives called the **gradient of the function** $\\nabla_\\mathbf{x} \\, f(\\mathbf{x})$:\n\n$$\n    \\nabla_\\mathbf{x} \\, f(\\mathbf{x}) = \\begin{bmatrix}\n        \\displaystyle\\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \\\\\n        \\displaystyle\\frac{\\partial f(\\mathbf{x})}{\\partial x_2} \\\\\n        \\ldots \\\\\n        \\displaystyle\\frac{\\partial f(\\mathbf{x})}{\\partial x_n} \\\\\n    \\end{bmatrix}\n$$\n\n\nThe subscript to the $\\nabla$ operator denotes *with respect to* (w.r.t) which variable the differentiation is done.\n\nA **partial derivative** w.r.t. to particular variable (or element of the vector) is simply achieved by differentiating the function while considering all other variables to be **constant**. For example the function:\n\n$$f(x, y) = x^2 + 3 \\, x \\, y + 4 \\, x \\, y^2 - 1$$\n\ncan be partially differentiated w.r.t. $x$ and $y$ as:\n\n$$\\begin{cases}\n\\displaystyle\\frac{\\partial f(x, y)}{\\partial x} = 2 \\, x + 3\\, y + 4 \\, y^2 \\\\\n\\\\\n\\displaystyle\\frac{\\partial f(x, y)}{\\partial y} = 3 \\, x + 8\\, x \\, y\n\\end{cases}$$\n\nThe gradient can be generalized to **vector fields**, where the **Jacobian** or **Jacobi matrix** is a matrix containing all partial derivatives.\n\n$$\nJ = \\begin{bmatrix}\n    \\dfrac{\\partial \\mathbf{f}}{\\partial x_1} & \\cdots & \\dfrac{\\partial \\mathbf{f}}{\\partial x_n} \\end{bmatrix}\n= \\begin{bmatrix}\n    \\dfrac{\\partial f_1}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_1}{\\partial x_n}\\\\\n    \\vdots & \\ddots & \\vdots\\\\\n    \\dfrac{\\partial f_m}{\\partial x_1} & \\cdots & \\dfrac{\\partial f_m}{\\partial x_n} \\end{bmatrix}\n$$\n\n#### Analytical properties\n\nThe analytical form of the derivative of most standard mathematical functions is known. The following table lists the most useful ones in this course:\n\n```{list-table}\n:header-rows: 1\n:name: example-table\n\n* - $f(x)$\n  - $f'(x)$\n* - $x$\n  - $1$\n* - $x^p$\n  - $p \\, x^{p-1}$\n* - $\\displaystyle\\frac{1}{x}$\n  - $- \\displaystyle\\frac{1}{x^2}$\n* - $e^x$\n  - $e^x$\n* - $\\ln x$\n  - $\\displaystyle\\frac{1}{x}$\nDifferentiation is linear, which means that if we define the function:\n\\[h(x) = a \\, f(x) + b \\, g(x)\\]\nits derivative is:\n\\[h'(x) = a \\, f'(x) + b \\, g'(x)\\]\nA product of functions can also be differentiated analytically:\n\\[(f(x) \\times g(x))' = f'(x) \\times g(x) + f(x) \\times g'(x)\\]\n```{admonition} Example \\[f(x) = x^2 \\, e^x\\]\n\\[f'(x) = 2 \\, x \\, e^x + x^2 \\cdot e^x\\]\n\n#### Chain rule\n\nA very important concept for neural networks is the **chain rule**, which tells how to differentiate **function compositions** (functions of a function) of the form:\n\n$$(f \\circ g) (x) = f(g(x))$$\n\nThe derivative of $f \\circ g$ is:\n\n$$(f \\circ g)' (x) = (f' \\circ g) (x) \\times g'(x)$$\n\nThe chain rule may be more understandable using Leibniz's notation:\n\n$$\\frac{d f \\circ g (x)}{dx} = \\frac{d f (g (x))}{d g(x)} \\times \\frac{d g (x)}{dx}$$\n\nBy posing $y = g(x)$ as an intermediary variable, it becomes:\n\n\n$$\\frac{d f(y)}{dx} = \\frac{d f(y)}{dy} \\times \\frac{dy}{dx}$$\n\n\n```{admonition} Example\nThe function :\n\n$$h(x) = \\frac{1}{2 \\, x + 1}$$\n\nis the function composition of $g(x) = 2 \\, x + 1$ and $f(x) = \\displaystyle\\frac{1}{x}$, whose derivatives are known:\n\n$$g'(x) = 2$$\n$$f'(x) = -\\displaystyle\\frac{1}{x^2}$$\n\nIts derivative according to the **chain rule** is:\n\n$$h'(x) = f'(g(x)) \\times g'(x) = -\\displaystyle\\frac{1}{(2 \\, x + 1)^2} \\times 2$$\nThe chain rule also applies to partial derivatives:\n\\[\n    \\displaystyle\\frac{\\partial f \\circ g (x, y)}{\\partial x} = \\frac{\\partial f \\circ g (x, y)}{\\partial g (x, y)} \\times \\frac{\\partial g (x, y)}{\\partial x}\n\\]\nand gradients:\n\\[\n    \\nabla_\\mathbf{x} \\, f \\circ g (\\mathbf{x}) = \\nabla_{g(\\mathbf{x})} \\, f \\circ g (\\mathbf{x}) \\times \\nabla_\\mathbf{x} \\, g (\\mathbf{x})\n\\]\n\n\n\n2.2.3 Integration\nThe opposite operation of differentation is integration. Given a function \\(f(x)\\), we search a function \\(F(x)\\) whose derivative is \\(f(x)\\):\n\\[F'(x) = f(x)\\]\nThe integral of \\(f\\) is noted:\n\\[F(x) = \\int f(x) \\, dx\\]\n\\(dx\\) being an infinitesimal interval (similar \\(h\\) in the definition of the derivative). There are tons of formal definitions of integrals (Riemann, Lebesgue, Darboux…) and we will not get into details here as we will not use integrals a lot.\nThe most important to understand for now is maybe that the integral of a function is the area under the curve. The area under the curve of a function \\(f\\) on the interval \\([a, b]\\) is:\n\\[\\mathcal{S} = \\int_a^b f(x) \\, dx\\]\n\n\n\n```{figure} ../img/riemann-sum1.svg\n\n\n\n\nwidth: 60%\n\n\n\nThe integral of \\(f\\) on \\([a, b]\\) is the area of the surface between the function and the x-axis. Note that it can become negative when the function is mostly negative on \\([a, b]\\). Source: https://www.math24.net/riemann-sums-definite-integral/\n\nOne way to approximate this surface is to split the interval $[a, b]$ into $n$ intervals of width $dx$ with the points $x_1, x_2, \\ldots, x_n$. This defines $n$ rectangles of width $dx$ and height $f(x_i)$, so their surface is $f(x_i) \\, dx$. The area under the curve can then be approximated by the sum of the surfaces of all these rectangles.\n\n```{figure} ../img/riemann-sum.svg\n---\nwidth: 60%\n---\nThe interval$[a, b]$ can be split in $n$ small intervals of width $dx$, defining $n$ rectangles whose sum is close to the area under the curve. Source: <https://www.math24.net/riemann-sums-definite-integral/>\nWhen \\(n \\to \\infty\\), or equivalently \\(dx \\to 0\\), the sum of these rectangular areas (called the Riemann sum) becomes exactly the area under the curve. This is the definition of the definite integral:\n\\[\\int_a^b f(x) \\, dx = \\lim_{dx \\to 0} \\sum_{i=1}^n f(x_i) \\, dx\\]\nVery roughly speaking, the integral can be considered as the equivalent of a sum for continuous functions."
  },
  {
    "objectID": "notes/1.2-Math.html#probability-theory",
    "href": "notes/1.2-Math.html#probability-theory",
    "title": "2  Math basics (optional)",
    "section": "2.3 Probability theory",
    "text": "2.3 Probability theory\n\n\n\n\n\n2.3.1 Discrete probability distributions\nLet’s note \\(X\\) a discrete random variable with \\(n\\) realizations (or outcomes) \\(x_1, \\ldots, x_n\\).\n\nA coin has two outcomes: head and tails.\nA dice has six outcomes: 1, 2, 3, 4, 5, 6.\n\nThe probability that \\(X\\) takes the value \\(x_i\\) is defined in the frequentist sense by the relative frequency of occurrence, i.e. the proportion of samples having the value \\(x_i\\), when the total number \\(N\\) of samples tends to infinity:\n\\[\n    P(X = x_i) = \\frac{\\text{Number of favorable cases}}{\\text{Total number of samples}}\n\\]\nThe set of probabilities \\(\\{P(X = x_i)\\}_{i=1}^n\\) define the probability distribution for the random variable (or probability mass function, pmf). By definition, we have \\(0 \\leq P(X = x_i) \\leq 1\\) and the probabilities have to respect:\n\\[\n    \\sum_{i=1}^n P(X = x_i) = 1\n\\]\nAn important metric for a random variable is its mathematical expectation or expected value, i.e. its “mean” realization weighted by the probabilities:\n\\[\n    \\mathbb{E}[X] = \\sum_{i=1}^n P(X = x_i) \\, x_i\n\\]\nThe expectation does not even need to be a valid realization:\n\\[\n    \\mathbb{E}[\\text{Coin}] = \\frac{1}{2} \\, 0 + \\frac{1}{2} \\, 1 = 0.5\n\\]\n\\[\n    \\mathbb{E}[\\text{Dice}] = \\frac{1}{6} \\, (1 + 2 + 3 + 4 + 5 + 6) = 3.5\n\\]\nWe can also compute the mathematical expectation of functions of a random variable:\n\\[\n    \\mathbb{E}[f(X)] = \\sum_{i=1}^n P(X = x_i) \\, f(x_i)\n\\]\nThe variance of a random variable is the squared deviation around the mean:\n\\[\n    \\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\sum_{i=1}^n P(X = x_i) \\, (x_i - \\mathbb{E}[X])^2\n\\]\nVariance of a coin:\n\\[\n    \\text{Var}(\\text{Coin}) = \\frac{1}{2} \\, (0 - 0.5)^2 + \\frac{1}{2} \\, (1 - 0.5)^2 = 0.25\n\\]\nVariance of a dice:\n\\[\n    \\text{Var}(\\text{Dice}) = \\frac{1}{6} \\, ((1-3.5)^2 + (2-3.5)^2 + (3-3.5)^2 + (4-3.5)^2 + (5-3.5)^2 + (6-3.5)^2) = \\frac{105}{36}\n\\]\n\n\n2.3.2 Continuous probability distributions\nContinuous random variables can take infinitely many values in a continuous interval, e.g. \\(\\Re\\) or some subset. The closed set of values they can take is called the support \\(\\mathcal{D}_X\\) of the probability distribution. The probability distribution is described by a probability density function (pdf) \\(f(x)\\).\n\n\n\n```{figure} ../img/normaldistribution.png\n\n\n\n\nwidth: 60%\n\n\n\nNormal distributions are continuous distributions. The area under the curve is always 1.\n\nThe pdf of a distribution must be positive ($f(x) \\geq 0 \\, \\forall x \\in \\mathcal{D}_X$) and its integral (area under the curve) must be equal to 1:\n\n$$\n    \\int_{x \\in \\mathcal{D}_X} f(x) \\, dx = 1\n$$\n\nThe pdf does not give the probability of taking a particular value $x$ (it is 0), but allows to get the probability that a value lies in a specific interval:\n\n$$\n    P(a \\leq X \\leq b) = \\int_{a}^b f(x) \\, dx \n$$\n\n\nOne can however think of the pdf as the **likelihood** that a value $x$ comes from that distribution.\n\n\nFor continuous distributions, the mathematical expectation is now defined by an integral instead of a sum:\n\n$$\n    \\mathbb{E}[X] = \\int_{x \\in \\mathcal{D}_X} f(x) \\, x \\, dx\n$$\n\nthe variance also:\n\n$$\n    \\text{Var}(X) = \\int_{x \\in \\mathcal{D}_X} f(x) \\, (x - \\mathbb{E}[X])^2 \\, dx\n$$\n\nor a function of the random variable:\n\n$$\n    \\mathbb{E}[g(X)] = \\int_{x \\in \\mathcal{D}_X} f(x) \\, g(x) \\, dx\n$$\n\nNote that the expectation operator is **linear**:\n\n$$\n    \\mathbb{E}[a \\, X + b \\, Y] = a \\, \\mathbb{E}[X] + b \\, \\mathbb{E}[Y]\n$$\n\nbut not the variance, even when the distributions are independent:\n\n$$\n    \\text{Var}[a \\, X + b \\, Y] = a^2 \\, \\text{Var}[X] + b^2 \\, \\text{Var}[Y]\n$$\n\n### Standard distributions\n\nProbability distributions can in principle have any form: $f(x)$ is unknown. However, specific parameterized distributions can be very useful: their pmf/pdf is fully determined by a couple of parameters.\n\n* The **Bernouilli** distribution is a binary (discrete, 0 or 1) distribution with a parameter $p$ specifying the probability to obtain the outcome 1 (e.g. a coin):\n\n$$\n    P(X = 1) = p \\; \\text{and} \\; P(X=0) = 1 - p \n$$\n$$P(X=x) = p^x \\, (1-p)^{1-x}$$\n$$\\mathbb{E}[X] = p$$\n\n* The **Multinouilli** or **categorical** distribution is a discrete distribution with $k$ realizations (e.g. a dice). Each realization $x_i$ is associated with a parameter $p_i >0$ representing its probability. We have $\\sum_i p_i = 1$.\n\n$$P(X = x_i) = p_i$$\n\n\n* The **uniform distribution** has an equal and constant probability of returning values between $a$ and $b$, never outside this range. It is parameterized by the start of the range $a$ and the end of the range $b$. Its support is $[a, b]$. The pdf of the uniform distribution $\\mathcal{U}(a, b)$ is defined on $[a, b]$ as:\n\n$$\n    f(x; a, b) = \\frac{1}{b - a}\n$$\n\n* The **normal distribution** is the most frequently encountered continuous distribution. It is parameterized by two parameters: the mean $\\mu$ and the variance $\\sigma^2$ (or standard deviation $\\sigma$). Its support is $\\Re$. The pdf of the normal distribution $\\mathcal{N}(\\mu, \\sigma)$ is defined on $\\Re$ as:\n\n$$\n    f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\,\\pi\\,\\sigma^2}} \\, e^{-\\displaystyle\\frac{(x - \\mu)^2}{2\\,\\sigma^2}}\n$$\n\n\n* The **exponential distribution** is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rate. It is parameterized by one parameter: the rate $\\lambda$. Its support is $\\Re^+$ ($x > 0$).\nThe pdf of the exponential distribution is defined on $\\Re^+$ as:\n\n$$\n    f(x; \\lambda) = \\lambda \\, e^{-\\lambda \\, x}\n$$\n\n\n### Joint and conditional probabilities\n\nLet's now suppose that we have two random variables $X$ and $Y$ with different probability distributions $P(X)$ and $P(Y)$.  The **joint probability** $P(X, Y)$ denotes the probability of observing the realizations $x$ **and** $y$ at the same time:\n\n$$P(X=x, Y=y)$$\n\nIf the random variables are **independent**, we have:\n\n$$P(X=x, Y=y) = P(X=x) \\, P(Y=y)$$\n\nIf you know the joint probability, you can compute the **marginal probability distribution** of each variable:\n\n$$P(X=x) = \\sum_y P(X=x, Y=y)$$\n\nThe same is true for continuous probability distributions:\n\n$$\n    f(x) = \\int f(x, y) \\, dy\n$$\n\nSome useful information between two random variables is the **conditional probability**. $P(X=x | Y=y)$ is the conditional probability that $X=x$, **given** that $Y=y$ is observed.\n\n* $Y=y$ is not random anymore: it is a **fact** (at least theoretically).\n\n* You wonder what happens to the probability distribution of $X$ now that you know the value of $Y$.\n\nConditional probabilities are linked to the joint probability by:\n\n$$\n    P(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\n$$\n\nIf $X$ and $Y$ are **independent**, we have $P(X=x | Y=y) = P(X=x)$ (knowing $Y$ does not change anything to the probability distribution of $X$). We can use the same notation for the complete probability distributions:\n\n$$\n    P(X | Y) = \\frac{P(X, Y)}{P(Y)}\n$$\n\n**Example**\n\n\n```{figure} ../img/conditionalprobability.png\n---\nwidth: 60%\n---\nSource: <https://www.elevise.co.uk/g-e-m-h-5-u.html>.\nYou ask 50 people whether they like cats or dogs:\n\n18 like both cats and dogs.\n21 like only dogs.\n5 like only cats.\n6 like none of them.\n\nWe consider loving cats and dogs as random variables (and that our sample size is big enough to use probabilities…). Among the 23 who love cats, which proportion also loves dogs?\n```{dropdown} Answer We have \\(P(\\text{dog}) = \\displaystyle\\frac{18+21}{50}= \\displaystyle\\frac{39}{50}\\) and \\(P(\\text{cat}) = \\displaystyle\\frac{18+5}{50} = \\frac{23}{50}\\).\nThe joint probability of loving both cats and dogs is \\(P(\\text{cat}, \\text{dog}) = \\displaystyle\\frac{18}{50}\\).\nThe conditional probability of loving dogs given one loves cats is:\n\\[P(\\text{dog} | \\text{cat}) = \\displaystyle\\frac{P(\\text{cat}, \\text{dog})}{P(\\text{cat})} = \\frac{\\frac{18}{50}}{\\frac{23}{50}} = \\frac{18}{23}\\]\n\n\n### Bayes' rule\n\nNoticing that the definition of conditional probabilities is symmetric:\n\n$$\n    P(X, Y) = P(X | Y) \\, P(Y) = P(Y | X) \\, P(X)\n$$\n\nwe can obtain the **Bayes' rule**:\n\n$$\n    P(Y | X) = \\frac{P(X|Y) \\, P(Y)}{P(X)}\n$$\n\nIt is very useful when you already know $P(X|Y)$ and want to obtain $P(Y|X)$ (**Bayesian inference**).\n\n* $P(Y | X)$ is called the **posterior probability**.\n\n* $P(X | Y)$ is called the **likelihood**.\n\n* $P(Y)$ is called the **prior probability** (belief).\n\n* $P(X)$ is called the **model evidence** or **marginal likelihood**.\n\n\n**Example**\n\nLet's consider a disease $D$ (binary random variable) and a medical test $T$ (also binary). The disease affects 10% of the general population: \n\n$$P(D=1)= 0.1 \\qquad \\qquad P(D=0)=0.9$$\n\nWhen a patient has the disease, the test is positive 80% of the time (true positives):\n\n$$P(T=1 | D=1) = 0.8 \\qquad \\qquad P(T=0 | D=1) = 0.2$$\n\nWhen a patient does not have the disease, the test is still positive 10% of the time (false positives):\n\n$$P(T=1 | D=0) = 0.1 \\qquad \\qquad P(T=0 | D=0) = 0.9$$\n\nGiven that the test is positive, what is the probability that the patient is ill?\n\n\n```{dropdown} Answer\n$$\n\\begin{aligned}\n    P(D=1|T=1) &= \\frac{P(T=1 | D=1) \\, P(D=1)}{P(T=1)} \\\\\n               &\\\\\n               &= \\frac{P(T=1 | D=1) \\, P(D=1)}{P(T=1 | D=1) \\, P(D=1) + P(T=1 | D=0) \\, P(D=0)} \\\\\n               &\\\\\n               &= \\frac{0.8 \\times 0.1}{0.8 \\times 0.1 + 0.1 \\times 0.9} \\\\\n               &\\\\\n               & = 0.47 \\\\\n\\end{aligned}\n$$"
  },
  {
    "objectID": "notes/1.2-Math.html#statistics",
    "href": "notes/1.2-Math.html#statistics",
    "title": "2  Math basics (optional)",
    "section": "2.4 Statistics",
    "text": "2.4 Statistics\n\n\n\n\n\n2.4.1 Monte Carlo sampling\nRandom sampling or Monte Carlo sampling (MC) consists of taking \\(N\\) samples \\(x_i\\) out of the distribution \\(X\\) (discrete or continuous) and computing the sample average:\n\\[\n    \\mathbb{E}[X] = \\mathbb{E}_{x \\sim X} [x] \\approx \\frac{1}{N} \\, \\sum_{i=1}^N x_i\n\\]\n\n\n\n```{figure} ../img/normaldistribution.svg\n\n\n\n\nwidth: 60%\n\n\n\nSamples taken from a normal distribution will mostly be around the mean.\n\nMore samples will be obtained where $f(x)$ is high ($x$ is probable), so the average of the sampled data will be close to the expected value of the distribution.\n\n**Law of big numbers**\n\n> As the number of identically distributed, randomly generated variables increases, their sample mean (average) approaches their theoretical mean.\n\n\nMC estimates are only correct when: \n\n* the samples are **i.i.d** (independent and identically distributed):\n\n    * independent: the samples must be unrelated with each other.\n\n    * identically distributed: the samples must come from the same distribution $X$.\n\n* the number of samples is large enough. Usually $N > 30$ for simple distributions.\n\nOne can estimate any function of the random variable with random sampling:\n\n$$\n    \\mathbb{E}[f(X)] = \\mathbb{E}_{x \\sim X} [f(x)] \\approx \\frac{1}{N} \\, \\sum_{i=1}^N f(x_i)\n$$\n\n```{figure} ../img/montecarlo.svg\n---\nwidth: 100%\n---\nSampling can be used to estimate $\\pi$: when sampling $x$ and $y$ uniformly in $[0, 1]$, the proportion of points with a norm smaller than tends to $\\pi/4$. Source: <https://towardsdatascience.com/an-overview-of-monte-carlo-methods-675384eb1694>\n\n\n2.4.2 Central limit theorem\nSuppose we have an unknown distribution \\(X\\) with expected value \\(\\mu = \\mathbb{E}[X]\\) and variance \\(\\sigma^2\\). We can take randomly \\(N\\) samples from \\(X\\) to compute the sample average:\n\\[\n    S_N = \\frac{1}{N} \\, \\sum_{i=1}^N x_i\n\\]\nThe Central Limit Theorem (CLT) states that:\n\nThe distribution of sample averages is normally distributed with mean \\(\\mu\\) and variance \\(\\frac{\\sigma^2}{N}\\).\n\n\\[S_N \\sim \\mathcal{N}(\\mu, \\frac{\\sigma}{\\sqrt{N}})\\]\nIf we perform the sampling multiple times, even with few samples, the average of the sampling averages will be very close to the expected value. The more samples we get, the smaller the variance of the estimates. Although the distribution \\(X\\) can be anything, the sampling averages are normally distributed.\n\n\n\n```{figure} ../img/IllustrationCentralTheorem.png\n\n\n\n\nwidth: 100%\n\n\n\nSource: https://en.wikipedia.org/wiki/Central_limit_theorem\n\n### Estimators\n\nCLT shows that the sampling average is an **unbiased estimator** of the expected value of a distribution:\n\n$$\\mathbb{E}[S_N] = \\mathbb{E}[X]$$\n\nAn estimator is a random variable used to measure parameters of a distribution (e.g. its expectation). The problem is that estimators can generally be **biased**.\n\nTake the example of a thermometer $M$ measuring the temperature $T$. $T$ is a random variable (normally distributed with $\\mu=20$ and $\\sigma=10$) and the measurements $M$ relate to the temperature with the relation:\n\n$$\n    M = 0.95 \\, T + 0.65\n$$\n\n```{figure} ../img/estimators-temperature.png\n---\nwidth: 100%\n---\nLeft: measurement as a function of the temperature. Right: distribution of temperature.\nThe thermometer is not perfect, but do random measurements allow us to estimate the expected value of the temperature?\nWe could repeatedly take 100 random samples of the thermometer and see how the distribution of sample averages look like:\n\n\n\n```{figure} ../img/estimators-temperature2.png\n\n\n\n\nwidth: 60%\n\n\n\nSampled measurements.\n\nBut, as the expectation is linear, we actually have:\n\n$$\n    \\mathbb{E}[M] = \\mathbb{E}[0.95 \\, T + 0.65] = 0.95 \\, \\mathbb{E}[T] + 0.65 = 19.65 \\neq \\mathbb{E}[T]\n$$\n\nThe thermometer is a **biased estimator** of the temperature.\n\nLet's note $\\theta$ a parameter of a probability distribution $X$ that we want to estimate (it does not have to be its mean). An **estimator** $\\hat{\\theta}$ is a random variable mapping the sample space of $X$ to a set of sample estimates.\n\n* The **bias** of an estimator is the mean error made by the estimator:\n\n$$\n    \\mathcal{B}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta} - \\theta] = \\mathbb{E}[\\hat{\\theta}] - \\theta\n$$\n\n* The **variance** of an estimator is the deviation of the samples around the expected value:\n\n$$\n    \\text{Var}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}] )^2]\n$$\n\nIdeally, we would like estimators with:\n\n* **low bias**: the estimations are correct on average (= equal to the true parameter).\n\n* **low variance**: we do not need many estimates to get a correct estimate (CLT: $\\frac{\\sigma}{\\sqrt{N}}$)\n\n\n```{figure} ../img/biasvariance3.png\n---\nwidth: 60%\n---\nBias-variance trade-off.\nUnfortunately, the perfect estimator does not exist in practice. One usually talks of a bias/variance trade-off: if you have a small bias, you will have a high variance, or vice versa. In machine learning, bias corresponds to underfitting, variance to overfitting."
  },
  {
    "objectID": "notes/1.2-Math.html#information-theory",
    "href": "notes/1.2-Math.html#information-theory",
    "title": "2  Math basics (optional)",
    "section": "2.5 Information theory",
    "text": "2.5 Information theory\n\n\n\n\n\n2.5.1 Entropy\nInformation theory (a field founded by Claude Shannon) asks how much information is contained in a probability distribution. Information is related to surprise or uncertainty: are the outcomes of a random variable surprising?\n\nAlmost certain outcomes (\\(P \\sim 1\\)) are not surprising because they happen all the time.\nAlmost impossible outcomes (\\(P \\sim 0\\)) are very surprising because they are very rare.\n\n\n\n\n```{figure} ../img/selfinformation.png\n\n\n\n\nwidth: 80%\n\n\n\nSelf-information.\n\nA useful measurement of how surprising is an outcome $x$ is the **self-information**:\n\n$$\n    I (x) = - \\log P(X = x)\n$$\n\nDepending on which log is used, self-information has different units, but it is just a rescaling, the base never matters:\n\n* $\\log_2$: bits or shannons.\n* $\\log_e = \\ln$: nats.\n\n\nThe **entropy** (or Shannon entropy) of a probability distribution is the expected value of the self-information of its outcomes:\n\n$$\n    H(X) = \\mathbb{E}_{x \\sim X} [I(x)] = \\mathbb{E}_{x \\sim X} [- \\log P(X = x)] \n$$\n\nIt measures the **uncertainty**, **randomness** or **information content** of the random variable.\n\nIn the discrete case:\n\n$$\n    H(X) = - \\sum_x P(x) \\, \\log P(x)\n$$\n\nIn the continuous case:\n\n$$\n    H(X) = - \\int_x f(x) \\, \\log f(x) \\, dx\n$$\n\nThe entropy of a Bernouilli variable is maximal when both outcomes are **equiprobable**. If a variable is **deterministic**, its entropy is minimal and equal to zero.\n\n\n```{figure} ../img/entropy-binomial.png\n---\nwidth: 80%\n---\nThe entropy of a Bernouilli distribution is maximal when the two outcomes are equiprobable.\nThe joint entropy of two random variables \\(X\\) and \\(Y\\) is defined by:\n\\[\n    H(X, Y) = \\mathbb{E}_{x \\sim X, y \\sim Y} [- \\log P(X=x, Y=y)]\n\\]\nThe conditional entropy of two random variables \\(X\\) and \\(Y\\) is defined by:\n\\[\n    H(X | Y) = \\mathbb{E}_{x \\sim X, y \\sim Y} [- \\log P(X=x | Y=y)]  = \\mathbb{E}_{x \\sim X, y \\sim Y} [- \\log \\frac{P(X=x , Y=y)}{P(Y=y)}]\n\\]\nIf the variables are independent, we have:\n\\[\n    H(X, Y) = H(X) + H(Y)\n\\] \\[\n    H(X | Y) = H(X)\n\\]\nBoth are related by:\n\\[\n    H(X | Y) = H(X, Y) - H(Y)\n\\]\nThe equivalent of Bayes’ rule is:\n\\[\n    H(Y |X) = H(X |Y) + H(Y) - H(X)\n\\]\n\n\n2.5.2 Mutual Information, cross-entropy and Kullback-Leibler divergence\nThe most important information measurement between two variables is the mutual information MI (or information gain):\n\\[\n    I(X, Y) = H(X) - H(X | Y) = H(Y) - H(Y | X)\n\\]\nIt measures how much information the variable \\(X\\) holds on \\(Y\\):\n\nIf the two variables are independent, the MI is 0 : \\(X\\) is as random, whether you know \\(Y\\) or not.\n\n\\[\n        I (X, Y) = 0\n\\]\n\nIf the two variables are dependent, knowing \\(Y\\) gives you information on \\(X\\), which becomes less random, i.e. less uncertain / surprising.\n\n\\[\n        I (X, Y) > 0\n\\]\nIf you can fully predict \\(X\\) when you know \\(Y\\), it becomes deterministic (\\(H(X|Y)=0\\)) so the mutual information is maximal (\\(I(X, Y) = H(X)\\)).\nThe cross-entropy between two distributions \\(X\\) and \\(Y\\) is defined as:\n\\[\n    H(X, Y) = \\mathbb{E}_{x \\sim X}[- \\log P(Y=x)]\n\\]\nBeware that the notation $H(X, Y)$ is the same as the joint entropy, but it is a different concept!\n\n\n\n```{figure} ../img/crossentropy.svg\n\n\n\n\nwidth: 100%\n\n\n\nThe cross-entropy measures the overlap between two probability distributions.\n\nThe cross-entropy measures the **negative log-likelihood** that a sample $x$ taken from the distribution $X$ could also come from the distribution $Y$. More exactly, it measures how many bits of information one would need to distinguish the two distributions $X$ and $Y$.\n\n$$\n    H(X, Y) = \\mathbb{E}_{x \\sim X}[- \\log P(Y=x)]\n$$\n\nIf the two distributions are the same *almost anywhere*, one cannot distinguish samples from the two distributions, the cross-entropy is the same as the entropy of $X$. If the two distributions are completely different, one can tell whether a sample $Z$ comes from $X$ or $Y$, the cross-entropy is higher than the entropy of $X$.\n\n\nIn practice, the **Kullback-Leibler divergence** $\\text{KL}(X ||Y)$ is a better measurement of the similarity (statistical distance) between two probability distributions:\n\n$$\n    \\text{KL}(X ||Y) = \\mathbb{E}_{x \\sim X}[- \\log \\frac{P(Y=x)}{P(X=x)}]\n$$\n\nIt is linked to the cross-entropy by:\n\n$$\n    \\text{KL}(X ||Y) = H(X, Y) - H(X)\n$$\n\nIf the two distributions are the same *almost anywhere*, the KL divergence is zero. If the two distributions are different, the KL divergence is positive. Minimizing the KL between two distributions is the same as making the two distributions \"equal\". But remember: the KL is not a metric, as it is not symmetric.\n\n\n\n```{note}\nRefer \n<https://towardsdatascience.com/entropy-cross-entropy-and-kl-divergence-explained-b09cdae917a> for nice visual explanantions of the cross-entropy.\n\n\n\n\nGoodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press."
  },
  {
    "objectID": "exercises/1-Python-solution.html",
    "href": "exercises/1-Python-solution.html",
    "title": "3  Introduction To Python",
    "section": "",
    "text": "Python is a powerful, flexible programming language widely used for scientific computing, in web/Internet development, to write desktop graphical user interfaces (GUIs), create games, and much more. It became the de facto standard for machine learning, with a huge variety of specialized libraries such as:\nPython is an high-level, interpreted, object-oriented language written in C, which means it is compiled on-the-fly, at run-time execution. Its syntax is close to C, but without prototyping (whether a variable is an integer or a string will be automatically determined by the context). It can be executed either directly in an interpreter (à la Matlab), in a script or in a notebook (as here).\nThe documentation on Python can be found at http://docs.python.org.\nMany resources to learn Python exist on the Web:\nThis notebook only introduces you to the basics, so feel free to study additional resources if you want to master Python programming."
  },
  {
    "objectID": "exercises/1-Python-solution.html#installation",
    "href": "exercises/1-Python-solution.html#installation",
    "title": "3  Introduction To Python",
    "section": "3.1 Installation",
    "text": "3.1 Installation\nPython should be already installed if you use Linux, a very old version if you use MacOS, and probably nothing under Windows. Moreover, Python 2.7 became obsolete in December 2019 but is still the default on some distributions.\nFor these reasons, we strongly recommend installing Python 3 using the Anaconda distribution:\nhttps://www.anaconda.com/products/individual\nAnaconda offers all the major Python packages in one place, with a focus on data science and machine learning. To install it, simply download the installer / script for your OS and follow the instructions. Beware, the installation takes quite a lot of space on the disk (around 1 GB), so choose the installation path wisely.\nTo install packages (for example tensorflow), you just have to type in a terminal:\nconda install tensorflow\nRefer to the docs (https://docs.anaconda.com/anaconda/) to know more. If you prefer your local Python installation, the pip utility allows to also install virtually any Python package:\npip install tensorflow\nAnother option is to run the notebooks in the cloud, for example on Google Colab:\nhttps://colab.research.google.com/\nColab has all major ML packages already installed, so you do not have to care about anything. Under conditions, you can also use a GPU for free (but for maximally 24 hours in a row)."
  },
  {
    "objectID": "exercises/1-Python-solution.html#working-with-python",
    "href": "exercises/1-Python-solution.html#working-with-python",
    "title": "3  Introduction To Python",
    "section": "3.2 Working With Python",
    "text": "3.2 Working With Python\nThere are basically three ways to program in Python: the interpreter for small commands, scripts for longer programs and notebooks (as here) for interactive programming.\n\n3.2.1 Python Interpreter\nTo start the Python interpreter, simply type its name in a terminal under Linux:\nuser@machine ~ $ python\nPython 3.7.4 (default, Jul 16 2019, 07:12:58) \n[GCC 9.1.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \nYou can then type anything at the prompt, for example a print statement:\n>>> print(\"Hello World!\")\nHello World!\nTo exit Python call the exit() function (or Ctrl+d):\n>>> exit()\n\n\n3.2.2 Scripts\nInstead of using the interpreter, you can run scripts which can be executed sequentially. Simply edit a text file called MyScript.py containing for example:\n# MyScript.py\n# Implements the Hello World example.\n\ntext = 'Hello World!' # define a string variable\n\nprint(text)\nThe # character is used for comments. Execute this script by typing in a Terminal:\npython MyScript.py\nAs it is a scripted language, each instruction in the script is executed from the beginning to the end, except for the declared functions or classes which can be used later.\n\n\n3.2.3 Jupyter Notebooks\nA third recent (but very useful) option is to use Jupyter notebooks (formerly IPython notebooks).\nJupyter notebooks allow you to edit Python code in your browser (but also Julia, R, Scala…) and run it locally.\nTo launch a Jupyter notebook, type in a terminal:\njupyter notebook\nand create a new notebook (Python 3)\nWhen a Jupyter notebook already exists (here 1-Python.ipynb), you can also start it directly:\njupyter notebook 1-Python.ipynb\nAlternatively, Jupyter lab has a more modern UI, but is still in beta.\nThe main particularity of notebooks is that code is not executed sequentially from the beginning to the end, but only when a cell is explicitly run with Ctrl + Enter (the active cell stays the same) or Shift + Enter (the next cell becomes active).\nTo edit a cell, select it and press Enter (or double-click).\nQ: In the next cell, run the Hello World! example:\n\ntext = 'Hello World!'\nprint(text)\n\nHello World!\n\n\nThere are three types of cells:\n\nPython cells allow to execute Python code (the default)\nMarkdown cells which allow to document the code nicely (code, equations), like the current one.\nRaw cell are passed to nbconvert directly, it allows you to generate html or pdf versions of your notebook (not used here).\n\nBeware that the order of execution of the cells matters!\nQ: In the next three cells, put the following commands:\n\ntext = \"Text A\"\ntext = \"Text B\"\nprint(text)\n\nand run them in different orders (e.g. 1, 2, 3, 1, 3)\n\ntext = \"Text A\"\n\n\ntext = \"Text B\"\n\n\nprint(text)\n\nText B\n\n\nExecuting a cell can therefore influence cells before and after it. If you want to run the notebook sequentially, select Kernel/Restart & Run all.\nTake a moment to explore the options in the menu (Insert cells, Run cells, Download as Python, etc)."
  },
  {
    "objectID": "exercises/1-Python-solution.html#basics-in-python",
    "href": "exercises/1-Python-solution.html#basics-in-python",
    "title": "3  Introduction To Python",
    "section": "3.3 Basics In Python",
    "text": "3.3 Basics In Python\n\n3.3.1 Print Statement\nIn Python 3, the print() function is a regular function:\nprint(value1, value2, ...)\nYou can give it as many arguments as you want (of whatever type), they will be printed one after another separated by spaces.\nQ: Try to print “Hello World!” using two different strings “Hello” and “World!”:\n\ntext1 = 'Hello'\ntext2 = \"World!\"\n\nprint(text1, text2)\n\nHello World!\n\n\n\n\n3.3.2 Data Types\nAs Python is an interpreted language, variables can be assigned without specifying their type: it will be inferred at execution time.\nThe only thing that counts is how you initialize them and which operations you perform on them.\na = 42          # Integer\nb = 3.14159     # Double precision float\nc = 'My string' # String\nd = False       # Boolean\ne = a > b       # Boolean\nQ: Print these variables as well as their type:\nprint(type(a))\n\na = 42          # Integer\nb = 3.14159     # Double precision float\nc = 'My string' # String\nd = False       # Boolean\ne = a > b       # Boolean\n\nprint('Value of a is', a,', Type of a is:', type(a))\nprint('Value of b is', b,', Type of b is:', type(b))\nprint('Value of c is', c,', Type of c is:', type(c))\nprint('Value of d is', d,', Type of d is:', type(d))\nprint('Value of e is', e,', Type of e is:', type(e))\n\nValue of a is 42 , Type of a is: <class 'int'>\nValue of b is 3.14159 , Type of b is: <class 'float'>\nValue of c is My string , Type of c is: <class 'str'>\nValue of d is False , Type of d is: <class 'bool'>\nValue of e is True , Type of e is: <class 'bool'>\n\n\n\n\n3.3.3 Assignment Statement And Operators\n\n3.3.3.1 Assignment Statement\nThe assignment can be done for a single variable, or for a tuple of variables separated by commas:\nm = 5 + 7\n\nx, y = 10, 20\n\na, b, c, d = 5, 'Text', None, x==y\nQ: Try these assignments and print the values of the variables.\n\nm = 5 + 7\nx, y = 10, 20\na, b, c, d = 5, 'Text', None, x==y\n\nprint(m, x, y, a, b, c, d,)\n\n12 10 20 5 Text None False\n\n\n\n\n3.3.3.2 Operators\nMost usual operators are available:\n+ , - , * , ** , / , // , %\n== , != , <> , > , >= , < , <=\nand , or , not\nQ: Try them and comment on their behaviour. Observe in particular what happens when you add an integer and a float.\n\nx = 3 + 5.\nprint(x, type(x))\n\n8.0 <class 'float'>\n\n\nQ: Notice how integer division is handled by python 3 by dividing an integer by either an integer or a float:\n\nprint(5/2)\nprint(5/2.)\n\n2.5\n2.5\n\n\n\n\n\n3.3.4 Strings\nA string in Python can be surrounded by either single or double quotes (no difference as long as they match). Three double quotes allow to print new lines directly (equivalent of \\n in C).\nQ: Use the function print() to see the results of the following statements:\na = 'abc'\n\nb = \"def\"\n\nc = \"\"\"aaa\nbbb\nccc\"\"\"\n\nd = \"xxx'yyy\"\n\ne = 'mmm\"nnn'\n\nf = \"aaa\\nbbb\\nccc\"\n\na = 'abc'\nb = \"def\"\nc = \"\"\"aaa\nbbb\nccc\"\"\"\nd = \"xxx'yyy\"\ne = 'mmm\"nnn'\nf = \"aaa\\nbbb\\nccc\"\n\nprint(a)\nprint(b)\nprint(c)\nprint(d)\nprint(e)\nprint(f)\n\nabc\ndef\naaa\nbbb\nccc\nxxx'yyy\nmmm\"nnn\naaa\nbbb\nccc\n\n\n\n\n3.3.5 Lists\nPython knows a number of compound data types, used to group together other values. The most versatile is the list, which can be written as a list of comma-separated values (items) between square brackets []. List items need not all to have the same type.\na = ['spam', 'eggs', 100, 1234]\nQ: Define a list of various variables and print it:\n\na = ['spam', 'eggs', 100, 1234]\n\nprint(a)\n\n['spam', 'eggs', 100, 1234]\n\n\nThe number of items in a list is available through the len() function applied to the list:\nlen(a)\nQ: Apply len() on the list, as well as on a string:\n\nprint(\"Length of the list:\", len(a))\nprint(\"Length of the word spam:\", len('spam'))\n\nLength of the list: 4\nLength of the word spam: 4\n\n\nTo access the elements of the list, indexing and slicing can be used.\n\nAs in C, indices start at 0, so a[0] is the first element of the list, a[3] is its fourth element.\nNegative indices start from the end of the list, so a[-1] is the last element, a[-2] the last but one, etc.\nSlices return a list containing a subset of elements, with the form a[start:stop], stop being excluded. a[1:3] returns the second and third elements. WHen omitted, start is 0 (a[:2] returns the two first elements) and stop is the length of the list (a[1:] has all elements of a except the first one).\n\nQ: Experiment with indexing and slicing on your list.\n\nprint(a)\nprint(\"a[0]\", a[0])\nprint(\"a[3]\", a[3])\nprint(\"a[-1]\", a[-1])\nprint(\"a[1:3]\", a[1:3])\n\n['spam', 'eggs', 100, 1234]\na[0] spam\na[3] 1234\na[-1] 1234\na[1:3] ['eggs', 100]\n\n\nCopying lists can cause some problems:\na = [1,2,3] # Initial list\n\nb = a # \"Copy\" the list by reference \n\na[0] = 9 # Change one item of the initial list\nQ: Now print a and b. What happens?\n\na = [1,2,3] # Initial list\n\nb = a # \"Copy\" the list by reference \n\na[0] = 9 # Change one item of the initial list\n\nprint('a :', a)\nprint('b :', b)\n\na : [9, 2, 3]\nb : [9, 2, 3]\n\n\nA: B = A does not make a copy of the content of A, but of its reference (pointer). So a and b both points at the same object.\nThe solution is to use the built-in copy() method of lists:\nb = a.copy()\nQ: Try it and observe the difference.\n\na = [1, 2, 3]\nb = a.copy()\na[0] = 9\n\nprint(a)\nprint(b)\n\n[9, 2, 3]\n[1, 2, 3]\n\n\nLists are objects, with a lot of different built-in methods (type help(list) in the interpreter or in a cell):\n\na.append(x): Add an item to the end of the list.\na.extend(L): Extend the list by appending all the items in the given list.\na.insert(i, x): Insert an item at a given position.\na.remove(x): Remove the first item from the list whose value is x.\na.pop(i): Remove the item at the given position in the list, and return it.\na.index(x): Return the index in the list of the first item whose value is x.\na.count(x): Return the number of times x appears in the list.\na.sort(): Sort the items of the list, in place.\na.reverse(): Reverse the elements of the list, in place.\n\nQ: Try out quickly these methods, in particular append() which we will use quite often.\n\na = [1, 2, 3]\n\na.append(4)\n\nprint(a)\n\n[1, 2, 3, 4]\n\n\n\n\n3.3.6 Dictionaries\nAnother useful data type built into Python is the dictionary. Unlike lists, which are indexed by a range of numbers from 0 to length -1, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys.\nDictionaries can be defined by curly braces {} instead of square brackets. The content is defined by key:item pairs, the item can be of any type:\ntel = {\n    'jack': 4098, \n    'sape': 4139\n}\nTo retrieve an item, simply use the key:\ntel_jack = tel['jack']\nTo add an entry to the dictionary, just use the key and assign a value to the item. It automatically extends the dictionary (warning, it can be dangerous!).\ntel['guido'] = 4127\nQ: Create a dictionary and elements to it.\n\ntel = {'jack': 4098, 'sape': 4139}\ntel_jack = tel['jack']\ntel['guido'] = 4127\n\nprint(tel)\nprint(tel_jack)\n\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n4098\n\n\nThe keys() method of a dictionary object returns a list of all the keys used in the dictionary, in the order in which you added the keys (if you want it sorted, just apply the sorted() function on it).\na = tel.keys()\nb = sorted(tel.keys())\nvalues() does the same for the value of the items:\nc = tel.values()\nQ: Do it on your dictionary.\n\na = tel.keys()\nb = sorted(a)\nc = tel.values()\n\nprint(a)\nprint(b)\nprint(c)\n\ndict_keys(['jack', 'sape', 'guido'])\n['guido', 'jack', 'sape']\ndict_values([4098, 4139, 4127])\n\n\n\n\n3.3.7 If Statement\nPerhaps the most well-known conditional statement type is the if statement. For example:\nif x < 0 :\n    print('x =', x, 'is negative')\nelif x == 0:\n    print('x =', x, 'is zero')\nelse:\n    print('x =', x, 'is positive')\nQ: Give a value to the variable x and see what this statement does.\n\nx = 5\n\nif x < 0 :\n    print('x =', x, 'is negative')\nelif x == 0:\n    print('x =', x, 'is zero')\nelse:\n    print('x =', x, 'is positive')\n\nx = 5 is positive\n\n\nImportant! The main particularity of the Python syntax is that the scope of the different structures (functions, for, if, while, etc…) is defined by the indentation, not by curly braces {}. As long as the code stays at the same level, it is in the same scope:\nif x < 0 :\n    print('x =', x, 'is negative')\n    x = -x\n    print('x =', x, 'is now positive')\nelif x == 0:\n    print('x =', x, 'is zero')\nelse:\n    print('x =', x, 'is positive')\nA reasonable choice is to use four spaces for the indentation instead of tabs (configure your text editor if you are not using Jupyter).\nWhen the scope is terminated, you need to come back at exactly the same level of indentation. Try this misaligned structure and observe what happens:\nif x < 0 :\n    print('x =', x, 'is negative')\n elif x == 0:\n    print('x =', x, 'is zero')\n else:\n    print('x =', x, 'is positive')\nJupyter is nice enough to highlight it for you, but not all text editors do that…\n\nif x < 0 :\n    print('x =', x, 'is negative')\n elif x == 0:\n    print('x =', x, 'is zero')\n else:\n    print('x =', x, 'is positive')\n\nIndentationError: unindent does not match any outer indentation level (<tokenize>, line 3)\n\n\nIn a if statement, there can be zero or more elif parts. What to do when the condition is true should be indented. The keyword \"elif\" is a shortened form of \"else if\", and is useful to avoid excessive indentation. An if ... elif ... elif ... sequence is a substitute for the switch or case statements found in other languages.\nThe elif and else statements are optional. You can also only use the if statement alone:\na = [1, 2, 0]\nhas_zero = False\nif 0 in a:\n    has_zero = True\nNote the use of the in keyword to know if an element exists in a list.\n\n\n3.3.8 For loops\nThe for statement in Python differs a bit from what you may be used to in C, Java or Pascal.\nRather than always iterating over an arithmetic progression of numbers (like in Pascal), or giving the user the ability to define both the iteration step and halting condition (as C), Python’s for statement iterates over the items of any sequence (a list or a string), in the order they appear in the sequence.\nlist_words = ['cat', 'window', 'defenestrate']\n\nfor word in list_words:\n    print(word, len(word))\nQ: Iterate over the list you created previously and print each element.\n\na = ['spam', 'eggs', 100, 1234]\n\nfor el in a:\n    print(el)\n\nspam\neggs\n100\n1234\n\n\nIf you do need to iterate over a sequence of numbers, the built-in function range() comes in handy. It generates lists containing arithmetic progressions:\nfor i in range(5):\n    print(i)\nQ: Try it.\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\nrange(N) generates a list of N number starting from 0 until N-1.\nIt is possible to specify a start value (0 by default), an end value (excluded) and even a step:\nrange(5, 10)\nrange(5, 10, 2)\nQ: Print the second and fourth elements of your list (['spam', 'eggs', 100, 1234]) using range().\n\nfor i in range(1, 4, 2):\n    print(a[i])\n\neggs\n1234\n\n\nTo iterate over all the indices of a list (0, 1, 2, etc), you can combine range() and len() as follows:\nfor idx in range(len(a)):\nThe enumerate() function allows to get at the same time the index and the content:\nfor i, val in enumerate(a):\n    print(i, val)\n\nfor i, val in enumerate(a):\n    print(i, val)\n\n0 spam\n1 eggs\n2 100\n3 1234\n\n\nTo get iteratively the keys and items of a dictionary, use the items() method of dictionary:\nfor key, val in tel.items():\nQ: Print one by one all keys and values of your dictionary.\n\ntel = {'jack': 4098, 'sape': 4139, 'guido': 4127}\n\nfor name, number in tel.items():\n    print(name, number)\n\njack 4098\nsape 4139\nguido 4127\n\n\n\n\n3.3.9 Functions\nAs in most procedural languages, you can define functions. Functions are defined by the keyword def. Only the parameters of the function are specified (without type), not the return values.\nThe content of the function has to be incremented as with for loops.\nReturn values can be specified with the return keywork. It is possible to return several values at the same time, separated by commas.\ndef say_hello_to(first, second):\n    question = 'Hello, I am '+ first + '!'\n    answer = 'Hello '+ first + '! I am ' + second + '!'\n    return question, answer\nTo call that function, pass the arguments that you need and retrieve the retruned values separated by commas.\nquestion, answer = say_hello_to('Jack', 'Gill')\nQ: Test it with different names as arguments.\n\ndef say_hello_to(first, second):\n    question = 'Hello, I am '+ first + '!'\n    answer = 'Hello '+ first + '! I am ' + second + '!'\n    return question, answer\n\nquestion, answer = say_hello_to('Jack', 'Gill')\n\nprint(question)\nprint(answer)\n\nHello, I am Jack!\nHello Jack! I am Gill!\n\n\nQ: Redefine the tel dictionary {'jack': 4098, 'sape': 4139, 'guido': 4127} if needed, and create a function that returns a list of names whose number is higher than 4100.\n\ndef filter_dict(tel):\n    answer = []\n    for name, number in tel.items():\n        if number >= 4100:\n            answer.append(name)\n    return answer\n\ntel = {'jack': 4098, 'sape': 4139, 'guido': 4127}\nnames = filter_dict(tel)\nprint(names)\n\n['sape', 'guido']\n\n\nFunctions can take several arguments (with default values or not). The name of the argument can be specified during the call, so their order won’t matter.\nQ: Try these different calls to the say_hello_to() function:\nquestion, answer = say_hello_to('Jack', 'Gill')\nquestion, answer = say_hello_to(first='Jack', second='Gill')\nquestion, answer = say_hello_to(second='Jack', first='Gill')\n\nquestion, answer = say_hello_to('Jack', 'Gill')\nprint(question)\nprint(answer)\nquestion, answer = say_hello_to(first='Jack', second='Gill')\nprint(question)\nprint(answer)\nquestion, answer = say_hello_to(second='Jack', first='Gill')\nprint(question)\nprint(answer)\n\nHello, I am Jack!\nHello Jack! I am Gill!\nHello, I am Jack!\nHello Jack! I am Gill!\nHello, I am Gill!\nHello Gill! I am Jack!\n\n\nDefault values can be specified for the last arguments, for example:\ndef add (a, b=1):\n    return a + b\n\nx = add(2, 3) # returns 5\ny = add(2) # returns 3\nz = add(a=4) # returns 5\nQ: Modify say_hello_to() so that the second argument is your own name by default.\n\ndef say_hello_to(first, second=\"Julien\"):\n    question = 'Hello, I am '+ first + '!'\n    answer = 'Hello '+ first + '! I am ' + second + '!'\n    return question, answer\n\nquestion, answer = say_hello_to('Jack', 'Gill')\nprint(question)\nprint(answer)\n\nquestion, answer = say_hello_to('Jack')\nprint(question)\nprint(answer)\n\nHello, I am Jack!\nHello Jack! I am Gill!\nHello, I am Jack!\nHello Jack! I am Julien!\n\n\n\n\n3.3.10 Classes\nClasses are structures allowing to:\n\nStore information in an object.\nApply functions on this information.\n\nIn a nutshell:\nclass Foo:\n    \n    def __init__(self, val):\n        self.val = val\n        \n    def print(self):\n        print(self.val)\n   \n    def set_val(self, val):\n        self.val = val\n        self.print()\n        \na = Foo(42)\na.print()\nThis defines the class Foo. The first (obligatory) method of the class is the constructor __init__. This determines how the instance a will be instantiated after the call to a = Foo(42). The first argument is self, which represents the current instance of the class. We can specify other arguments to the constructor (here val), which can be processed or stored.\nHere we store val as an attribute of the class Foo with self.val. It is data that will be specific to each created object: if you create b = Foo(\"deep learning\"), the attribute self.val will have different values between the two instances. As always in Python, the type does not matter, it can be a float, a string, a numpy array, another object…\nAttributes are accessible from each object as:\nx = a.val\nYou can set its value by:\na.val = 12\nClasses can define methods that can manipulate class attributes like any regular function. The first argument must always be self. With the self object, you can access all attributes (or other methods) of the instance.\nWith our toy class, a.set_val(34) does exactly the same as a.val = 34, or a.print() is the same as print(a.val).\nFor C++/Java experts: attributes and methods are always public in Python. If you want to make an attribute private, preprend its name with an underscore, e.g. self._val. It will then not be part of the API of the class (but can be read or written publicly anyway…).\nQ: Play around with this basic class, create different objects with different attributes, print them, change them, etc.\n\nclass Foo:\n    \n    def __init__(self, val):\n        self.val = val\n    \n    def print(self):\n        print(self.val)\n    \n    def set_val(self, val):\n        self.val = val\n        self.print()\n\na = Foo(42)\na.print()\nprint(a.val)\na.set_val(32)\na.print()\n\n42\n42\n32\n32\n\n\nA major concept in object-oriented programming (OOP) is class inheritance. We will not use it much in these exercises, but let’s talk shortly about it.\nInheriting a class is creating a new class that inherits from the attributes and methods of another class (a kind of “copy” of the definition of the class). You can then add new attributes or methods, or overload existing ones.\nExample:\nclass Bar(Foo):\n    def add(self, val):\n        self.val += val\n    def print(self):\n        print(\"val =\", self.val)\nBar is a child class of Foo. It inherits all attributes and methods, including __init__, print and set_val. It creates a new method add and overloads print: the old definition of print in Foo does not exist anymore for instances of the Bar class (but does for instances of the Foo class). The constructor can also be overloaded, for example to add new arguments:\nclass Bar(Foo):\n    def __init__(self, val, val2):\n        self.val2 = val2\n        super().__init__(val)\n    def add(self, val):\n        self.val += val\n    def print(self):\n        print(\"val =\", self.val)\nsuper().__init__(val) calls the constructor of the Foo class (the “super” class of bar), so it sets the value of self.val.\nQ: Play around with inheritance to understand the concept.\n\nclass Bar(Foo):\n    def __init__(self, val, val2):\n        self.val2 = val2\n        super().__init__(val)\n    def add(self, val):\n        self.val += val\n    def print(self):\n        print(\"val =\", self.val)\n        \nb = Bar(12, 23)\nb.add(30)\nb.print()\n\nval = 42"
  },
  {
    "objectID": "exercises/1-Python-solution.html#exercise",
    "href": "exercises/1-Python-solution.html#exercise",
    "title": "3  Introduction To Python",
    "section": "3.4 Exercise",
    "text": "3.4 Exercise\nIn cryptography, a Caesar cipher is a very simple encryption technique in which each letter in the plain text is replaced by a letter some fixed number of positions down the alphabet. For example, with a shift of 3, A would be replaced by D, B would become E, and so on. The method is named after Julius Caesar, who used it to communicate with his generals. ROT-13 (“rotate by 13 places”) is a widely used example of a Caesar cipher where the shift is 13. In Python, the key for ROT-13 may be represented by means of the following dictionary:\n\ncode = {'a':'n', 'b':'o', 'c':'p', 'd':'q', 'e':'r', 'f':'s',\n        'g':'t', 'h':'u', 'i':'v', 'j':'w', 'k':'x', 'l':'y',\n        'm':'z', 'n':'a', 'o':'b', 'p':'c', 'q':'d', 'r':'e',\n        's':'f', 't':'g', 'u':'h', 'v':'i', 'w':'j', 'x':'k',\n        'y':'l', 'z':'m', 'A':'N', 'B':'O', 'C':'P', 'D':'Q',\n        'E':'R', 'F':'S', 'G':'T', 'H':'U', 'I':'V', 'J':'W',\n        'K':'X', 'L':'Y', 'M':'Z', 'N':'A', 'O':'B', 'P':'C',\n        'Q':'D', 'R':'E', 'S':'F', 'T':'G', 'U':'H', 'V':'I', \n        'W':'J', 'X':'K', 'Y':'L', 'Z':'M'}\n\nQ: Your task in this final exercise is to implement an encoder/decoder of ROT-13. Once you’re done, you will be able to read the following secret message:\nJnvg, jung qbrf vg unir gb qb jvgu qrrc yrneavat??\nThe idea is to write a decode() function taking the message and the code dictionary as inputs, and returning the decoded message. It should iterate over all letters of the message and replace them with the decoded letter. If the letter is not in the dictionary (e.g. punctuation), keep it as it is.\n\n# Method to decode a message\ndef decode(msg, code):\n    result = \"\"\n    for letter in msg:\n        if letter in code.keys():\n            result += code[letter]\n        else:\n            result += letter\n    return result\n\n# Message to decode\nmsg = \"Jnvg, jung qbrf vg unir gb qb jvgu qrrc yrneavat??\"\n\n# Decode the message\ndecoded = decode(msg, code)\nprint(decoded)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chollet, F. (2017). Deep Learning with\nPython. Manning publications.\n\n\nGoodfellow, I., Bengio, Y., and Courville, A. (2016). Deep\nLearning. MIT Press.\n\n\nHaykin, S. S. (2009). Neural Networks and\nLearning Machines, 3rd Edition.\nPearson."
  }
]